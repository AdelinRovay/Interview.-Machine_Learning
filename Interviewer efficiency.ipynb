{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from scipy import signal\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ad/Downloads/Interview ML'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_excel('/Users/ad/Downloads/Interview ML/Training Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Data fit for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interviewer Name</th>\n",
       "      <th>Interviwer  qualification</th>\n",
       "      <th>Interviwer Experience</th>\n",
       "      <th>Interviewer Age</th>\n",
       "      <th>Interviwer Skills</th>\n",
       "      <th>Interviwer Nationality</th>\n",
       "      <th>Interviewer Location</th>\n",
       "      <th>candidate</th>\n",
       "      <th>candidate  qualification</th>\n",
       "      <th>candidate Experience</th>\n",
       "      <th>...</th>\n",
       "      <th>candidate Skills</th>\n",
       "      <th>candidate Nationality</th>\n",
       "      <th>candidate Location</th>\n",
       "      <th>Interview Month</th>\n",
       "      <th>Interview time</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Interviewer Efficiency</th>\n",
       "      <th>Result</th>\n",
       "      <th>1st Year Performance</th>\n",
       "      <th>Failed Candidate Career Progression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I1</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>OIC, OCI</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>C1</td>\n",
       "      <td>BS</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>OIC, OCI</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>January</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>p</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Outstanding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I2</td>\n",
       "      <td>BSc</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>HCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>C2</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>HCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>February</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>f</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joined superior competition at higher level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I3</td>\n",
       "      <td>MBA</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>ERP Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>C3</td>\n",
       "      <td>MBA</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>ERP Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>February</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>p</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Meets Expectations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I4</td>\n",
       "      <td>MCA</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>CX Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>C4</td>\n",
       "      <td>MS</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>CX Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>March</td>\n",
       "      <td>12:00:00</td>\n",
       "      <td>Face to Face</td>\n",
       "      <td>p</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joined inferior competition at the same/lower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I5</td>\n",
       "      <td>Bcom</td>\n",
       "      <td>7</td>\n",
       "      <td>32</td>\n",
       "      <td>SCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>C5</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>SCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>March</td>\n",
       "      <td>14:00:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>f</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stayed in current company - promoted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>I16</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>OIC, OCI</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>C496</td>\n",
       "      <td>MS</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>OIC, OCI</td>\n",
       "      <td>US</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>November</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>p</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Outstanding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>I17</td>\n",
       "      <td>BSc</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>HCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>C497</td>\n",
       "      <td>MBA</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>HCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>December</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>p</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joined inferior competition at the same/lower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>I18</td>\n",
       "      <td>MBA</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>ERP Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>C498</td>\n",
       "      <td>MCA</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>ERP Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>December</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>Face to Face</td>\n",
       "      <td>p</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Outstanding</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>I19</td>\n",
       "      <td>MCA</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>CX Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>C499</td>\n",
       "      <td>MS</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>CX Cloud</td>\n",
       "      <td>US</td>\n",
       "      <td>New York</td>\n",
       "      <td>December</td>\n",
       "      <td>15:30:00</td>\n",
       "      <td>Face to Face</td>\n",
       "      <td>f</td>\n",
       "      <td>Fail</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Joined superior competition at the same/lower ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>I20</td>\n",
       "      <td>Bcom</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "      <td>SCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>C500</td>\n",
       "      <td>B.Tech</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>SCM Cloud</td>\n",
       "      <td>India</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>December</td>\n",
       "      <td>14:30:00</td>\n",
       "      <td>Video</td>\n",
       "      <td>f</td>\n",
       "      <td>Pass</td>\n",
       "      <td>Below expectations</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Interviewer Name Interviwer  qualification  Interviwer Experience  \\\n",
       "0                 I1                    B.Tech                      5   \n",
       "1                 I2                       BSc                     10   \n",
       "2                 I3                       MBA                     15   \n",
       "3                 I4                       MCA                      5   \n",
       "4                 I5                      Bcom                      7   \n",
       "..               ...                       ...                    ...   \n",
       "495              I16                    B.Tech                     10   \n",
       "496              I17                       BSc                     16   \n",
       "497              I18                       MBA                      8   \n",
       "498              I19                       MCA                      6   \n",
       "499              I20                      Bcom                     13   \n",
       "\n",
       "     Interviewer Age Interviwer Skills Interviwer Nationality  \\\n",
       "0                 28          OIC, OCI                     US   \n",
       "1                 35         HCM Cloud                  India   \n",
       "2                 45         ERP Cloud                  India   \n",
       "3                 30          CX Cloud                     US   \n",
       "4                 32         SCM Cloud                  India   \n",
       "..               ...               ...                    ...   \n",
       "495               38          OIC, OCI                     US   \n",
       "496               51         HCM Cloud                  India   \n",
       "497               30         ERP Cloud                  India   \n",
       "498               27          CX Cloud                     US   \n",
       "499               34         SCM Cloud                  India   \n",
       "\n",
       "    Interviewer Location candidate candidate  qualification  \\\n",
       "0                Atlanta        C1                       BS   \n",
       "1              Bangalore        C2                   B.Tech   \n",
       "2              Hyderabad        C3                      MBA   \n",
       "3               New York        C4                       MS   \n",
       "4                 Mumbai        C5                   B.Tech   \n",
       "..                   ...       ...                      ...   \n",
       "495              Atlanta      C496                       MS   \n",
       "496            Bangalore      C497                      MBA   \n",
       "497            Hyderabad      C498                      MCA   \n",
       "498             New York      C499                       MS   \n",
       "499               Mumbai      C500                   B.Tech   \n",
       "\n",
       "     candidate Experience  ...  candidate Skills candidate Nationality  \\\n",
       "0                       5  ...          OIC, OCI                    US   \n",
       "1                       8  ...         HCM Cloud                 India   \n",
       "2                      13  ...         ERP Cloud                 India   \n",
       "3                       5  ...          CX Cloud                    US   \n",
       "4                       6  ...         SCM Cloud                 India   \n",
       "..                    ...  ...               ...                   ...   \n",
       "495                     7  ...          OIC, OCI                    US   \n",
       "496                     9  ...         HCM Cloud                 India   \n",
       "497                    14  ...         ERP Cloud                 India   \n",
       "498                    12  ...          CX Cloud                    US   \n",
       "499                    11  ...         SCM Cloud                 India   \n",
       "\n",
       "    candidate Location Interview Month Interview time          Mode  \\\n",
       "0              Atlanta         January       09:00:00         Video   \n",
       "1            Bangalore        February       10:00:00         Video   \n",
       "2            Hyderabad        February       10:00:00         Video   \n",
       "3             New York           March       12:00:00  Face to Face   \n",
       "4               Mumbai           March       14:00:00         Video   \n",
       "..                 ...             ...            ...           ...   \n",
       "495            Atlanta        November       11:00:00         Video   \n",
       "496          Bangalore        December       11:30:00         Video   \n",
       "497          Hyderabad        December       09:00:00  Face to Face   \n",
       "498           New York        December       15:30:00  Face to Face   \n",
       "499             Mumbai        December       14:30:00         Video   \n",
       "\n",
       "    Interviewer Efficiency Result 1st Year Performance  \\\n",
       "0                        p   Pass          Outstanding   \n",
       "1                        f   Fail                  NaN   \n",
       "2                        p   Pass   Meets Expectations   \n",
       "3                        p   Fail                  NaN   \n",
       "4                        f   Fail                  NaN   \n",
       "..                     ...    ...                  ...   \n",
       "495                      p   Pass          Outstanding   \n",
       "496                      p   Fail                  NaN   \n",
       "497                      p   Pass          Outstanding   \n",
       "498                      f   Fail                  NaN   \n",
       "499                      f   Pass   Below expectations   \n",
       "\n",
       "                   Failed Candidate Career Progression  \n",
       "0                                                  NaN  \n",
       "1          Joined superior competition at higher level  \n",
       "2                                                  NaN  \n",
       "3    Joined inferior competition at the same/lower ...  \n",
       "4                 Stayed in current company - promoted  \n",
       "..                                                 ...  \n",
       "495                                                NaN  \n",
       "496  Joined inferior competition at the same/lower ...  \n",
       "497                                                NaN  \n",
       "498  Joined superior competition at the same/lower ...  \n",
       "499                                                NaN  \n",
       "\n",
       "[500 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.iloc[: , :-1]\n",
    "data2 = data2.iloc[: , :-1]\n",
    "data2 = data2.iloc[: , :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=\"Interviwer Experience\"\n",
    "data2[column]=data2[column]/data2[column].abs().max()\n",
    "column=\"Interviewer Age\"\n",
    "data2[column]=data2[column]/data2[column].abs().max()\n",
    "column=\"candidate Experience\"\n",
    "data2[column]=data2[column]/data2[column].abs().max()\n",
    "column=\"candidate Age\"\n",
    "data2[column]=data2[column]/data2[column].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data2['Interviwer Nationality'])\n",
    "data2 = data2.drop('Interviwer Nationality',axis = 1)\n",
    "data2 = data2.join(one_hot)\n",
    "data2=data2.rename(columns = {'India': 'Indian Interviewer', 'US': 'American Intervierwer'}, inplace = False)\n",
    "one_hot = pd.get_dummies(data2['candidate Nationality'])\n",
    "data2 = data2.drop('candidate Nationality',axis = 1)\n",
    "data2 = data2.join(one_hot)\n",
    "data2=data2.rename(columns = {'India': 'Indian Candidate', 'US': 'American Candidate'}, inplace = False)\n",
    "one_hot = pd.get_dummies(data2['Mode'])\n",
    "data2 = data2.drop('Mode',axis = 1)\n",
    "data2 = data2.join(one_hot)\n",
    "data2['Interview Month'].replace({\"January\": \"Q1\", \"February\":\"Q1\",\"March\":\"Q1\",\"April\":\"Q2\",\"May\":\"Q2\",\"June\":\"Q2\",\"July\":\"Q3\",\"August\":\"Q3\",\"September\":\"Q3\",\"October\":\"Q4\",\"November\":\"Q4\",\"December\":\"Q4\"}, inplace=True)\n",
    "one_hot = pd.get_dummies(data2['Interview Month'])\n",
    "data2 = data2.drop('Interview Month',axis = 1)\n",
    "data2 = data2.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop('Interviewer Name',axis = 1)\n",
    "data2 = data2.drop('candidate',axis = 1)\n",
    "data2 = data2.drop('Interviewer Location',axis = 1)\n",
    "data2 = data2.drop('candidate Location',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['Interviwer  qualification'].replace({\"BSc\": 0.2, \"Bcom\": 0.4,\"MCA\":0.6,'B.Tech':0.8,\"MBA\":1}, inplace=True)\n",
    "data2['candidate  qualification'].replace({\"BS\": 0.2, \"MCA\": 0.4,\"B.Tech\":0.6,'MS':0.8,\"MBA\":1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(data2['Interviwer Skills'])\n",
    "data2 = data2.drop('Interviwer Skills',axis = 1)\n",
    "data2 = data2.join(one_hot)\n",
    "data2=data2.rename(columns = {'CX Cloud': 'CX Cloud(I)', 'ERP Cloud': 'ERP Cloud(I)','HCM Cloud':'HCM Cloud(I)','OIC, OCI':'OIC, OCI(I)','SCM Cloud':'SCM Cloud(I)'}, inplace = False)\n",
    "one_hot = pd.get_dummies(data2['candidate Skills'])\n",
    "data2 = data2.drop('candidate Skills',axis = 1)\n",
    "data2 = data2.join(one_hot)\n",
    "data2=data2.rename(columns = {'CX Cloud': 'CX Cloud(C)', 'ERP Cloud': 'ERP Cloud(C)','HCM Cloud':'HCM Cloud(C)','OIC, OCI':'OIC, OCI(C)','SCM Cloud':'SCM Cloud(C)'}, inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list=data2[\"Interview time\"].tolist()\n",
    "l=[]\n",
    "for item in time_list:\n",
    "    l.append(str(item))\n",
    "data2['Interview time']=l\n",
    "data2['Interview time'].replace({'08:00:00':'Morning', '09:00:00':'Morning', '10:00:00':'Morning', '10:30:00':'Morning', '11:00:00':'Morning','11:30:00':'Morning', '12:00:00':'Morning', '12:30:00':'Afternoon', '13:00:00':'Afternoon', '13:30:00':'Afternoon','14:00:00':'Afternoon', '14:30:00':'Afternoon', '15:00:00':'Afternoon', '15:30:00':'Afternoon', '16:00:00':'Afternoon','17:00:00':'Evening', '17:30:00':'Evening', '18:00:00':'Evening', '19:00:00':'Evening', '20:00:00':'Evening','21:00:00':'Evening'}, inplace=True)\n",
    "one_hot = pd.get_dummies(data2['Interview time'])\n",
    "data2 = data2.drop('Interview time',axis = 1)\n",
    "data2 = data2.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2['Result'].replace({\"Pass\": 1, \"Fail\":0}, inplace=True)\n",
    "one_hot = pd.get_dummies(data2['Interviewer Efficiency'])\n",
    "data2 = data2.drop('Interviewer Efficiency',axis = 1)\n",
    "data2 = data2.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Interviwer  qualification</th>\n",
       "      <th>Interviwer Experience</th>\n",
       "      <th>Interviewer Age</th>\n",
       "      <th>candidate  qualification</th>\n",
       "      <th>candidate Experience</th>\n",
       "      <th>candidate Age</th>\n",
       "      <th>Indian Interviewer</th>\n",
       "      <th>American Intervierwer</th>\n",
       "      <th>Indian Candidate</th>\n",
       "      <th>American Candidate</th>\n",
       "      <th>...</th>\n",
       "      <th>CX Cloud(C)</th>\n",
       "      <th>ERP Cloud(C)</th>\n",
       "      <th>HCM Cloud(C)</th>\n",
       "      <th>OIC, OCI(C)</th>\n",
       "      <th>SCM Cloud(C)</th>\n",
       "      <th>Afternoon</th>\n",
       "      <th>Evening</th>\n",
       "      <th>Morning</th>\n",
       "      <th>f</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.686275</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.674419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Interviwer  qualification  Interviwer Experience  Interviewer Age  \\\n",
       "0                          0.8               0.277778         0.549020   \n",
       "1                          0.2               0.555556         0.686275   \n",
       "2                          1.0               0.833333         0.882353   \n",
       "3                          0.6               0.277778         0.588235   \n",
       "4                          0.4               0.388889         0.627451   \n",
       "..                         ...                    ...              ...   \n",
       "495                        0.8               0.555556         0.745098   \n",
       "496                        0.2               0.888889         1.000000   \n",
       "497                        1.0               0.444444         0.588235   \n",
       "498                        0.6               0.333333         0.529412   \n",
       "499                        0.4               0.722222         0.666667   \n",
       "\n",
       "     candidate  qualification  candidate Experience  candidate Age  \\\n",
       "0                         0.2              0.357143       0.604651   \n",
       "1                         0.6              0.571429       0.767442   \n",
       "2                         1.0              0.928571       0.976744   \n",
       "3                         0.8              0.357143       0.674419   \n",
       "4                         0.6              0.428571       0.720930   \n",
       "..                        ...                   ...            ...   \n",
       "495                       0.8              0.500000       0.767442   \n",
       "496                       1.0              0.642857       0.720930   \n",
       "497                       0.4              1.000000       0.813953   \n",
       "498                       0.8              0.857143       0.744186   \n",
       "499                       0.6              0.785714       0.790698   \n",
       "\n",
       "     Indian Interviewer  American Intervierwer  Indian Candidate  \\\n",
       "0                     0                      1                 0   \n",
       "1                     1                      0                 1   \n",
       "2                     1                      0                 1   \n",
       "3                     0                      1                 0   \n",
       "4                     1                      0                 1   \n",
       "..                  ...                    ...               ...   \n",
       "495                   0                      1                 0   \n",
       "496                   1                      0                 1   \n",
       "497                   1                      0                 1   \n",
       "498                   0                      1                 0   \n",
       "499                   1                      0                 1   \n",
       "\n",
       "     American Candidate  ...  CX Cloud(C)  ERP Cloud(C)  HCM Cloud(C)  \\\n",
       "0                     1  ...            0             0             0   \n",
       "1                     0  ...            0             0             1   \n",
       "2                     0  ...            0             1             0   \n",
       "3                     1  ...            1             0             0   \n",
       "4                     0  ...            0             0             0   \n",
       "..                  ...  ...          ...           ...           ...   \n",
       "495                   1  ...            0             0             0   \n",
       "496                   0  ...            0             0             1   \n",
       "497                   0  ...            0             1             0   \n",
       "498                   1  ...            1             0             0   \n",
       "499                   0  ...            0             0             0   \n",
       "\n",
       "     OIC, OCI(C)  SCM Cloud(C)  Afternoon  Evening  Morning  f  p  \n",
       "0              1             0          0        0        1  0  1  \n",
       "1              0             0          0        0        1  1  0  \n",
       "2              0             0          0        0        1  0  1  \n",
       "3              0             0          0        0        1  0  1  \n",
       "4              0             1          1        0        0  1  0  \n",
       "..           ...           ...        ...      ...      ... .. ..  \n",
       "495            1             0          0        0        1  0  1  \n",
       "496            0             0          0        0        1  0  1  \n",
       "497            0             0          0        0        1  0  1  \n",
       "498            0             0          1        0        0  1  0  \n",
       "499            0             1          1        0        0  1  0  \n",
       "\n",
       "[500 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target=data2['Result']\n",
    "#target=target.to_numpy()\n",
    "#data2 = data2.drop('Result',axis = 1)\n",
    "#data2=data2.to_numpy()\n",
    "target=data2.iloc[:,[29,30]]\n",
    "data2=data2.drop('p',axis=1)\n",
    "data2=data2.drop('f',axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(data2, target,test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Dense(256,input_shape=(29,),activation='sigmoid'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128,activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64,activation='sigmoid'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.005)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               7680      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 48,962\n",
      "Trainable params: 48,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7564 - accuracy: 0.6334\n",
      "Pre-training accuracy: 62.0000%\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "accuracy = 100*score[1]\n",
    "\n",
    "print(\"Pre-training accuracy: %.4f%%\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "100/100 [==============================] - 1s 3ms/step - loss: 0.7427 - accuracy: 0.5100 - val_loss: 0.6633 - val_accuracy: 0.6200\n",
      "Epoch 2/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7076 - accuracy: 0.5625 - val_loss: 0.6833 - val_accuracy: 0.6200\n",
      "Epoch 3/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6954 - accuracy: 0.5725 - val_loss: 0.6794 - val_accuracy: 0.6200\n",
      "Epoch 4/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.5475 - val_loss: 0.6786 - val_accuracy: 0.6200\n",
      "Epoch 5/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6867 - accuracy: 0.5400 - val_loss: 0.6612 - val_accuracy: 0.6200\n",
      "Epoch 6/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6896 - accuracy: 0.5650 - val_loss: 0.6565 - val_accuracy: 0.6200\n",
      "Epoch 7/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6846 - accuracy: 0.5750 - val_loss: 0.6542 - val_accuracy: 0.6200\n",
      "Epoch 8/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6755 - accuracy: 0.5575 - val_loss: 0.6503 - val_accuracy: 0.6200\n",
      "Epoch 9/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6801 - accuracy: 0.5775 - val_loss: 0.6446 - val_accuracy: 0.6200\n",
      "Epoch 10/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.6125 - val_loss: 0.6626 - val_accuracy: 0.5800\n",
      "Epoch 11/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6605 - accuracy: 0.6200 - val_loss: 0.6286 - val_accuracy: 0.5800\n",
      "Epoch 12/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6100 - val_loss: 0.6475 - val_accuracy: 0.5800\n",
      "Epoch 13/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.6250 - val_loss: 0.6660 - val_accuracy: 0.6000\n",
      "Epoch 14/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6000 - val_loss: 0.6550 - val_accuracy: 0.5800\n",
      "Epoch 15/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6050 - val_loss: 0.6369 - val_accuracy: 0.5800\n",
      "Epoch 16/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6585 - accuracy: 0.5925 - val_loss: 0.6434 - val_accuracy: 0.6200\n",
      "Epoch 17/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5950 - val_loss: 0.6409 - val_accuracy: 0.5700\n",
      "Epoch 18/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6629 - accuracy: 0.6025 - val_loss: 0.6425 - val_accuracy: 0.5600\n",
      "Epoch 19/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6511 - accuracy: 0.6300 - val_loss: 0.6563 - val_accuracy: 0.6000\n",
      "Epoch 20/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5975 - val_loss: 0.6331 - val_accuracy: 0.5700\n",
      "Epoch 21/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6615 - accuracy: 0.5875 - val_loss: 0.6380 - val_accuracy: 0.5800\n",
      "Epoch 22/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6125 - val_loss: 0.6385 - val_accuracy: 0.5600\n",
      "Epoch 23/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.5875 - val_loss: 0.6337 - val_accuracy: 0.5800\n",
      "Epoch 24/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.5850 - val_loss: 0.6474 - val_accuracy: 0.6200\n",
      "Epoch 25/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6610 - accuracy: 0.6000 - val_loss: 0.6480 - val_accuracy: 0.6300\n",
      "Epoch 26/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6521 - accuracy: 0.6050 - val_loss: 0.6394 - val_accuracy: 0.5600\n",
      "Epoch 27/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.6300 - val_loss: 0.6570 - val_accuracy: 0.5800\n",
      "Epoch 28/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.6425 - val_loss: 0.6659 - val_accuracy: 0.5600\n",
      "Epoch 29/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6050 - val_loss: 0.6540 - val_accuracy: 0.5800\n",
      "Epoch 30/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6605 - accuracy: 0.5800 - val_loss: 0.6375 - val_accuracy: 0.5600\n",
      "Epoch 31/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6025 - val_loss: 0.6544 - val_accuracy: 0.6100\n",
      "Epoch 32/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6547 - accuracy: 0.6125 - val_loss: 0.6130 - val_accuracy: 0.5900\n",
      "Epoch 33/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6554 - accuracy: 0.5825 - val_loss: 0.6330 - val_accuracy: 0.6200\n",
      "Epoch 34/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.6000 - val_loss: 0.6379 - val_accuracy: 0.5600\n",
      "Epoch 35/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.5975 - val_loss: 0.6349 - val_accuracy: 0.6000\n",
      "Epoch 36/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5600 - val_loss: 0.6408 - val_accuracy: 0.5600\n",
      "Epoch 37/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6515 - accuracy: 0.5950 - val_loss: 0.6297 - val_accuracy: 0.6200\n",
      "Epoch 38/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6200 - val_loss: 0.6543 - val_accuracy: 0.5700\n",
      "Epoch 39/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.5850 - val_loss: 0.6420 - val_accuracy: 0.5600\n",
      "Epoch 40/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.5850 - val_loss: 0.6419 - val_accuracy: 0.5600\n",
      "Epoch 41/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.6225 - val_loss: 0.6431 - val_accuracy: 0.5900\n",
      "Epoch 42/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6125 - val_loss: 0.6459 - val_accuracy: 0.5600\n",
      "Epoch 43/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6544 - accuracy: 0.6250 - val_loss: 0.6502 - val_accuracy: 0.5600\n",
      "Epoch 44/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6536 - accuracy: 0.6275 - val_loss: 0.6388 - val_accuracy: 0.5800\n",
      "Epoch 45/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6589 - accuracy: 0.6250 - val_loss: 0.6515 - val_accuracy: 0.5500\n",
      "Epoch 46/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6523 - accuracy: 0.6050 - val_loss: 0.6398 - val_accuracy: 0.6000\n",
      "Epoch 47/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.6025 - val_loss: 0.6361 - val_accuracy: 0.5900\n",
      "Epoch 48/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6553 - accuracy: 0.5900 - val_loss: 0.6553 - val_accuracy: 0.5600\n",
      "Epoch 49/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.6175 - val_loss: 0.6343 - val_accuracy: 0.5800\n",
      "Epoch 50/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.6100 - val_loss: 0.6426 - val_accuracy: 0.5600\n",
      "Epoch 51/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6494 - accuracy: 0.6150 - val_loss: 0.6338 - val_accuracy: 0.5900\n",
      "Epoch 52/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6200 - val_loss: 0.6464 - val_accuracy: 0.5700\n",
      "Epoch 53/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.6225 - val_loss: 0.6409 - val_accuracy: 0.5900\n",
      "Epoch 54/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6150 - val_loss: 0.6445 - val_accuracy: 0.5600\n",
      "Epoch 55/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6075 - val_loss: 0.6433 - val_accuracy: 0.5700\n",
      "Epoch 56/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6275 - val_loss: 0.6315 - val_accuracy: 0.5900\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6532 - accuracy: 0.6275 - val_loss: 0.6396 - val_accuracy: 0.5500\n",
      "Epoch 58/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6125 - val_loss: 0.6436 - val_accuracy: 0.5600\n",
      "Epoch 59/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.6300 - val_loss: 0.6420 - val_accuracy: 0.5500\n",
      "Epoch 60/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.6325 - val_loss: 0.6531 - val_accuracy: 0.5600\n",
      "Epoch 61/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.6200 - val_loss: 0.6504 - val_accuracy: 0.5700\n",
      "Epoch 62/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6535 - accuracy: 0.6250 - val_loss: 0.6362 - val_accuracy: 0.5800\n",
      "Epoch 63/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6506 - accuracy: 0.6175 - val_loss: 0.6364 - val_accuracy: 0.5700\n",
      "Epoch 64/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6375 - val_loss: 0.6435 - val_accuracy: 0.5700\n",
      "Epoch 65/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6275 - val_loss: 0.6409 - val_accuracy: 0.5900\n",
      "Epoch 66/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6450 - accuracy: 0.6075 - val_loss: 0.6340 - val_accuracy: 0.5900\n",
      "Epoch 67/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6325 - val_loss: 0.6420 - val_accuracy: 0.5700\n",
      "Epoch 68/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6300 - val_loss: 0.6377 - val_accuracy: 0.5800\n",
      "Epoch 69/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6375 - val_loss: 0.6422 - val_accuracy: 0.5800\n",
      "Epoch 70/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6494 - accuracy: 0.6375 - val_loss: 0.6400 - val_accuracy: 0.5800\n",
      "Epoch 71/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6400 - val_loss: 0.6420 - val_accuracy: 0.5800\n",
      "Epoch 72/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6325 - val_loss: 0.6491 - val_accuracy: 0.5800\n",
      "Epoch 73/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.6450 - val_loss: 0.6435 - val_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6622 - accuracy: 0.6075 - val_loss: 0.6575 - val_accuracy: 0.6000\n",
      "Epoch 75/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6598 - accuracy: 0.5925 - val_loss: 0.6376 - val_accuracy: 0.5700\n",
      "Epoch 76/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6350 - val_loss: 0.6390 - val_accuracy: 0.5700\n",
      "Epoch 77/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6475 - val_loss: 0.6499 - val_accuracy: 0.5800\n",
      "Epoch 78/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6375 - val_loss: 0.6493 - val_accuracy: 0.5800\n",
      "Epoch 79/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6275 - val_loss: 0.6419 - val_accuracy: 0.5700\n",
      "Epoch 80/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6250 - val_loss: 0.6416 - val_accuracy: 0.5700\n",
      "Epoch 81/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.6400 - val_loss: 0.6430 - val_accuracy: 0.5700\n",
      "Epoch 82/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6375 - val_loss: 0.6419 - val_accuracy: 0.5800\n",
      "Epoch 83/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6425 - val_loss: 0.6496 - val_accuracy: 0.5800\n",
      "Epoch 84/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6025 - val_loss: 0.6386 - val_accuracy: 0.5800\n",
      "Epoch 85/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6425 - val_loss: 0.6462 - val_accuracy: 0.5800\n",
      "Epoch 86/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.6300 - val_loss: 0.6440 - val_accuracy: 0.5700\n",
      "Epoch 87/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6475 - val_loss: 0.6433 - val_accuracy: 0.5800\n",
      "Epoch 88/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6449 - accuracy: 0.6350 - val_loss: 0.6454 - val_accuracy: 0.5700\n",
      "Epoch 89/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6500 - val_loss: 0.6449 - val_accuracy: 0.5800\n",
      "Epoch 90/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6400 - val_loss: 0.6482 - val_accuracy: 0.5700\n",
      "Epoch 91/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6400 - val_loss: 0.6408 - val_accuracy: 0.5800\n",
      "Epoch 92/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6250 - val_loss: 0.6369 - val_accuracy: 0.5800\n",
      "Epoch 93/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6482 - accuracy: 0.6425 - val_loss: 0.6431 - val_accuracy: 0.5800\n",
      "Epoch 94/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6425 - val_loss: 0.6417 - val_accuracy: 0.5800\n",
      "Epoch 95/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6575 - val_loss: 0.6425 - val_accuracy: 0.5800\n",
      "Epoch 96/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6425 - val_loss: 0.6442 - val_accuracy: 0.5800\n",
      "Epoch 97/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6483 - accuracy: 0.6350 - val_loss: 0.6457 - val_accuracy: 0.5700\n",
      "Epoch 98/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.5950 - val_loss: 0.6325 - val_accuracy: 0.5700\n",
      "Epoch 99/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6525 - val_loss: 0.6391 - val_accuracy: 0.5700\n",
      "Epoch 100/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6465 - accuracy: 0.6300 - val_loss: 0.6417 - val_accuracy: 0.5800\n",
      "Epoch 101/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6400 - val_loss: 0.6467 - val_accuracy: 0.5800\n",
      "Epoch 102/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.6175 - val_loss: 0.6398 - val_accuracy: 0.5800\n",
      "Epoch 103/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6275 - val_loss: 0.6376 - val_accuracy: 0.5800\n",
      "Epoch 104/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6250 - val_loss: 0.6477 - val_accuracy: 0.5700\n",
      "Epoch 105/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6525 - val_loss: 0.6455 - val_accuracy: 0.5700\n",
      "Epoch 106/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6400 - val_loss: 0.6448 - val_accuracy: 0.5700\n",
      "Epoch 107/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.6525 - val_loss: 0.6452 - val_accuracy: 0.5700\n",
      "Epoch 108/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6350 - val_loss: 0.6450 - val_accuracy: 0.5600\n",
      "Epoch 109/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.6275 - val_loss: 0.6417 - val_accuracy: 0.5700\n",
      "Epoch 110/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6250 - val_loss: 0.6432 - val_accuracy: 0.5700\n",
      "Epoch 111/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6525 - val_loss: 0.6467 - val_accuracy: 0.5900\n",
      "Epoch 112/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6375 - val_loss: 0.6491 - val_accuracy: 0.5700\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6450 - val_loss: 0.6408 - val_accuracy: 0.5800\n",
      "Epoch 114/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6200 - val_loss: 0.6411 - val_accuracy: 0.5700\n",
      "Epoch 115/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6375 - val_loss: 0.6435 - val_accuracy: 0.5800\n",
      "Epoch 116/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6375 - val_loss: 0.6468 - val_accuracy: 0.5800\n",
      "Epoch 117/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6425 - val_loss: 0.6470 - val_accuracy: 0.5800\n",
      "Epoch 118/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.6300 - val_loss: 0.6470 - val_accuracy: 0.5800\n",
      "Epoch 119/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6475 - val_loss: 0.6422 - val_accuracy: 0.5800\n",
      "Epoch 120/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6430 - accuracy: 0.6350 - val_loss: 0.6394 - val_accuracy: 0.5800\n",
      "Epoch 121/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6375 - val_loss: 0.6399 - val_accuracy: 0.5800\n",
      "Epoch 122/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6499 - accuracy: 0.6275 - val_loss: 0.6371 - val_accuracy: 0.5800\n",
      "Epoch 123/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6475 - val_loss: 0.6384 - val_accuracy: 0.5800\n",
      "Epoch 124/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6525 - val_loss: 0.6360 - val_accuracy: 0.5800\n",
      "Epoch 125/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6434 - accuracy: 0.6450 - val_loss: 0.6468 - val_accuracy: 0.5700\n",
      "Epoch 126/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6408 - accuracy: 0.6400 - val_loss: 0.6407 - val_accuracy: 0.5800\n",
      "Epoch 127/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.6400 - val_loss: 0.6413 - val_accuracy: 0.5800\n",
      "Epoch 128/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6450 - val_loss: 0.6511 - val_accuracy: 0.5800\n",
      "Epoch 129/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6395 - accuracy: 0.6425 - val_loss: 0.6455 - val_accuracy: 0.5800\n",
      "Epoch 130/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6450 - val_loss: 0.6451 - val_accuracy: 0.5700\n",
      "Epoch 131/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6400 - val_loss: 0.6435 - val_accuracy: 0.5800\n",
      "Epoch 132/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.6350 - val_loss: 0.6465 - val_accuracy: 0.5700\n",
      "Epoch 133/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6425 - accuracy: 0.6400 - val_loss: 0.6402 - val_accuracy: 0.5800\n",
      "Epoch 134/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6475 - val_loss: 0.6403 - val_accuracy: 0.5800\n",
      "Epoch 135/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6450 - val_loss: 0.6398 - val_accuracy: 0.5800\n",
      "Epoch 136/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6400 - val_loss: 0.6365 - val_accuracy: 0.5800\n",
      "Epoch 137/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6422 - accuracy: 0.6500 - val_loss: 0.6419 - val_accuracy: 0.5800\n",
      "Epoch 138/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6475 - val_loss: 0.6461 - val_accuracy: 0.5800\n",
      "Epoch 139/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6475 - val_loss: 0.6387 - val_accuracy: 0.5700\n",
      "Epoch 140/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6525 - val_loss: 0.6479 - val_accuracy: 0.5800\n",
      "Epoch 141/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6475 - val_loss: 0.6390 - val_accuracy: 0.5800\n",
      "Epoch 142/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6450 - val_loss: 0.6473 - val_accuracy: 0.5700\n",
      "Epoch 143/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6500 - val_loss: 0.6511 - val_accuracy: 0.5800\n",
      "Epoch 144/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6450 - val_loss: 0.6573 - val_accuracy: 0.5700\n",
      "Epoch 145/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6450 - val_loss: 0.6514 - val_accuracy: 0.5800\n",
      "Epoch 146/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6475 - val_loss: 0.6485 - val_accuracy: 0.5800\n",
      "Epoch 147/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6380 - accuracy: 0.6375 - val_loss: 0.6409 - val_accuracy: 0.5800\n",
      "Epoch 148/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6400 - val_loss: 0.6364 - val_accuracy: 0.5800\n",
      "Epoch 149/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6500 - val_loss: 0.6408 - val_accuracy: 0.5800\n",
      "Epoch 150/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6475 - val_loss: 0.6563 - val_accuracy: 0.5800\n",
      "Epoch 151/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6356 - accuracy: 0.6400 - val_loss: 0.6375 - val_accuracy: 0.5800\n",
      "Epoch 152/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6450 - val_loss: 0.6399 - val_accuracy: 0.5700\n",
      "Epoch 153/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6400 - val_loss: 0.6417 - val_accuracy: 0.5700\n",
      "Epoch 154/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6425 - val_loss: 0.6378 - val_accuracy: 0.5800\n",
      "Epoch 155/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.6450 - val_loss: 0.6409 - val_accuracy: 0.5800\n",
      "Epoch 156/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6354 - accuracy: 0.6450 - val_loss: 0.6399 - val_accuracy: 0.5800\n",
      "Epoch 157/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6420 - accuracy: 0.6475 - val_loss: 0.6401 - val_accuracy: 0.5800\n",
      "Epoch 158/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6425 - val_loss: 0.6398 - val_accuracy: 0.5800\n",
      "Epoch 159/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6425 - val_loss: 0.6406 - val_accuracy: 0.5800\n",
      "Epoch 160/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6400 - val_loss: 0.6459 - val_accuracy: 0.5700\n",
      "Epoch 161/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6427 - accuracy: 0.6275 - val_loss: 0.6412 - val_accuracy: 0.5700\n",
      "Epoch 162/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6435 - accuracy: 0.6400 - val_loss: 0.6471 - val_accuracy: 0.5800\n",
      "Epoch 163/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6425 - val_loss: 0.6582 - val_accuracy: 0.5800\n",
      "Epoch 164/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6484 - accuracy: 0.6400 - val_loss: 0.6403 - val_accuracy: 0.5800\n",
      "Epoch 165/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6522 - accuracy: 0.6475 - val_loss: 0.6391 - val_accuracy: 0.5800\n",
      "Epoch 166/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6400 - val_loss: 0.6416 - val_accuracy: 0.5800\n",
      "Epoch 167/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6375 - val_loss: 0.6392 - val_accuracy: 0.5800\n",
      "Epoch 168/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6400 - val_loss: 0.6360 - val_accuracy: 0.5700\n",
      "Epoch 169/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6450 - val_loss: 0.6372 - val_accuracy: 0.5800\n",
      "Epoch 170/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6450 - val_loss: 0.6337 - val_accuracy: 0.5800\n",
      "Epoch 171/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6450 - val_loss: 0.6366 - val_accuracy: 0.5800\n",
      "Epoch 172/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6450 - val_loss: 0.6381 - val_accuracy: 0.5800\n",
      "Epoch 173/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6475 - val_loss: 0.6443 - val_accuracy: 0.5800\n",
      "Epoch 174/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6375 - accuracy: 0.6525 - val_loss: 0.6410 - val_accuracy: 0.5800\n",
      "Epoch 175/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6375 - val_loss: 0.6402 - val_accuracy: 0.5700\n",
      "Epoch 176/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6417 - accuracy: 0.6525 - val_loss: 0.6314 - val_accuracy: 0.5700\n",
      "Epoch 177/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6463 - accuracy: 0.6275 - val_loss: 0.6397 - val_accuracy: 0.5800\n",
      "Epoch 178/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6050 - val_loss: 0.6375 - val_accuracy: 0.5800\n",
      "Epoch 179/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6325 - val_loss: 0.6409 - val_accuracy: 0.5600\n",
      "Epoch 180/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6475 - val_loss: 0.6435 - val_accuracy: 0.5800\n",
      "Epoch 181/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.5700\n",
      "Epoch 182/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.6300 - val_loss: 0.6427 - val_accuracy: 0.5800\n",
      "Epoch 183/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6415 - accuracy: 0.6275 - val_loss: 0.6417 - val_accuracy: 0.5900\n",
      "Epoch 184/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6469 - accuracy: 0.6300 - val_loss: 0.6410 - val_accuracy: 0.5800\n",
      "Epoch 185/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6575 - val_loss: 0.6446 - val_accuracy: 0.5800\n",
      "Epoch 186/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6460 - accuracy: 0.6325 - val_loss: 0.6478 - val_accuracy: 0.5800\n",
      "Epoch 187/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.6425 - val_loss: 0.6427 - val_accuracy: 0.5800\n",
      "Epoch 188/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6425 - val_loss: 0.6477 - val_accuracy: 0.5800\n",
      "Epoch 189/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6450 - val_loss: 0.6427 - val_accuracy: 0.5700\n",
      "Epoch 190/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6250 - val_loss: 0.6413 - val_accuracy: 0.5800\n",
      "Epoch 191/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6425 - val_loss: 0.6475 - val_accuracy: 0.6100\n",
      "Epoch 192/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.6300 - val_loss: 0.6375 - val_accuracy: 0.5700\n",
      "Epoch 193/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6450 - val_loss: 0.6402 - val_accuracy: 0.5800\n",
      "Epoch 194/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6375 - val_loss: 0.6413 - val_accuracy: 0.5800\n",
      "Epoch 195/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6360 - accuracy: 0.6525 - val_loss: 0.6491 - val_accuracy: 0.5700\n",
      "Epoch 196/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6450 - val_loss: 0.6469 - val_accuracy: 0.5700\n",
      "Epoch 197/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6525 - val_loss: 0.6485 - val_accuracy: 0.5800\n",
      "Epoch 198/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6439 - accuracy: 0.6375 - val_loss: 0.6448 - val_accuracy: 0.5800\n",
      "Epoch 199/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6350 - val_loss: 0.6427 - val_accuracy: 0.5800\n",
      "Epoch 200/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6613 - accuracy: 0.6275 - val_loss: 0.6544 - val_accuracy: 0.5900\n",
      "Epoch 201/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6529 - accuracy: 0.6300 - val_loss: 0.6383 - val_accuracy: 0.5800\n",
      "Epoch 202/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6418 - accuracy: 0.6375 - val_loss: 0.6483 - val_accuracy: 0.5800\n",
      "Epoch 203/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6550 - val_loss: 0.6503 - val_accuracy: 0.5800\n",
      "Epoch 204/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6475 - val_loss: 0.6624 - val_accuracy: 0.5700\n",
      "Epoch 205/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6550 - val_loss: 0.6548 - val_accuracy: 0.5800\n",
      "Epoch 206/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6550 - val_loss: 0.6630 - val_accuracy: 0.5800\n",
      "Epoch 207/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6450 - val_loss: 0.6437 - val_accuracy: 0.5700\n",
      "Epoch 208/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6450 - val_loss: 0.6614 - val_accuracy: 0.5800\n",
      "Epoch 209/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6500 - val_loss: 0.6515 - val_accuracy: 0.5800\n",
      "Epoch 210/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.6400 - val_loss: 0.6434 - val_accuracy: 0.5800\n",
      "Epoch 211/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.6450 - val_loss: 0.6421 - val_accuracy: 0.5800\n",
      "Epoch 212/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6425 - val_loss: 0.6376 - val_accuracy: 0.5800\n",
      "Epoch 213/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6429 - accuracy: 0.6425 - val_loss: 0.6452 - val_accuracy: 0.5800\n",
      "Epoch 214/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6468 - accuracy: 0.6475 - val_loss: 0.6406 - val_accuracy: 0.5800\n",
      "Epoch 215/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6400 - val_loss: 0.6415 - val_accuracy: 0.5800\n",
      "Epoch 216/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.6475 - val_loss: 0.6449 - val_accuracy: 0.5800\n",
      "Epoch 217/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6500 - val_loss: 0.6453 - val_accuracy: 0.5800\n",
      "Epoch 218/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6525 - val_loss: 0.6360 - val_accuracy: 0.5800\n",
      "Epoch 219/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.6400 - val_loss: 0.6475 - val_accuracy: 0.5800\n",
      "Epoch 220/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.6500 - val_loss: 0.6411 - val_accuracy: 0.5800\n",
      "Epoch 221/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6425 - val_loss: 0.6435 - val_accuracy: 0.5800\n",
      "Epoch 222/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6327 - accuracy: 0.6500 - val_loss: 0.6515 - val_accuracy: 0.5900\n",
      "Epoch 223/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.6450 - val_loss: 0.6499 - val_accuracy: 0.5800\n",
      "Epoch 224/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6462 - accuracy: 0.6400 - val_loss: 0.6491 - val_accuracy: 0.5800\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6377 - accuracy: 0.6625 - val_loss: 0.6428 - val_accuracy: 0.5800\n",
      "Epoch 226/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.6400 - val_loss: 0.6490 - val_accuracy: 0.5700\n",
      "Epoch 227/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6567 - accuracy: 0.6350 - val_loss: 0.6461 - val_accuracy: 0.5800\n",
      "Epoch 228/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6347 - accuracy: 0.6350 - val_loss: 0.6289 - val_accuracy: 0.5700\n",
      "Epoch 229/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.6450 - val_loss: 0.6484 - val_accuracy: 0.5900\n",
      "Epoch 230/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6400 - val_loss: 0.6518 - val_accuracy: 0.5800\n",
      "Epoch 231/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.6425 - val_loss: 0.6513 - val_accuracy: 0.5900\n",
      "Epoch 232/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6453 - accuracy: 0.6400 - val_loss: 0.6552 - val_accuracy: 0.5800\n",
      "Epoch 233/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6350 - val_loss: 0.6508 - val_accuracy: 0.5800\n",
      "Epoch 234/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6474 - accuracy: 0.6375 - val_loss: 0.6443 - val_accuracy: 0.5800\n",
      "Epoch 235/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6396 - accuracy: 0.6450 - val_loss: 0.6523 - val_accuracy: 0.5800\n",
      "Epoch 236/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.6650 - val_loss: 0.6488 - val_accuracy: 0.5900\n",
      "Epoch 237/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6575 - val_loss: 0.6634 - val_accuracy: 0.5800\n",
      "Epoch 238/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6400 - val_loss: 0.6472 - val_accuracy: 0.5800\n",
      "Epoch 239/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6375 - val_loss: 0.6527 - val_accuracy: 0.5700\n",
      "Epoch 240/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6442 - accuracy: 0.6475 - val_loss: 0.6445 - val_accuracy: 0.5900\n",
      "Epoch 241/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6225 - val_loss: 0.6451 - val_accuracy: 0.5900\n",
      "Epoch 242/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6465 - accuracy: 0.6375 - val_loss: 0.6450 - val_accuracy: 0.5900\n",
      "Epoch 243/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6400 - val_loss: 0.6396 - val_accuracy: 0.5800\n",
      "Epoch 244/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6350 - val_loss: 0.6460 - val_accuracy: 0.5900\n",
      "Epoch 245/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6375 - val_loss: 0.6501 - val_accuracy: 0.5800\n",
      "Epoch 246/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6550 - val_loss: 0.6496 - val_accuracy: 0.5800\n",
      "Epoch 247/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6500 - val_loss: 0.6479 - val_accuracy: 0.5800\n",
      "Epoch 248/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6425 - val_loss: 0.6487 - val_accuracy: 0.5800\n",
      "Epoch 249/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6425 - val_loss: 0.6432 - val_accuracy: 0.5800\n",
      "Epoch 250/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6444 - accuracy: 0.6500 - val_loss: 0.6499 - val_accuracy: 0.5800\n",
      "Epoch 251/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6425 - val_loss: 0.6523 - val_accuracy: 0.5700\n",
      "Epoch 252/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6425 - accuracy: 0.6425 - val_loss: 0.6484 - val_accuracy: 0.5800\n",
      "Epoch 253/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6425 - val_loss: 0.6582 - val_accuracy: 0.5800\n",
      "Epoch 254/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.6375 - val_loss: 0.6445 - val_accuracy: 0.5800\n",
      "Epoch 255/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6250 - val_loss: 0.6416 - val_accuracy: 0.5800\n",
      "Epoch 256/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6400 - val_loss: 0.6497 - val_accuracy: 0.5800\n",
      "Epoch 257/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6425 - val_loss: 0.6376 - val_accuracy: 0.5800\n",
      "Epoch 258/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6275 - val_loss: 0.6422 - val_accuracy: 0.5800\n",
      "Epoch 259/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6525 - val_loss: 0.6421 - val_accuracy: 0.5900\n",
      "Epoch 260/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.6450 - val_loss: 0.6410 - val_accuracy: 0.5900\n",
      "Epoch 261/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.6400 - val_loss: 0.6343 - val_accuracy: 0.5800\n",
      "Epoch 262/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6450 - val_loss: 0.6307 - val_accuracy: 0.5900\n",
      "Epoch 263/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.6475 - val_loss: 0.6333 - val_accuracy: 0.5800\n",
      "Epoch 264/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6550 - val_loss: 0.6404 - val_accuracy: 0.5800\n",
      "Epoch 265/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6375 - val_loss: 0.6457 - val_accuracy: 0.5800\n",
      "Epoch 266/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6447 - accuracy: 0.6400 - val_loss: 0.6423 - val_accuracy: 0.5800\n",
      "Epoch 267/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6475 - val_loss: 0.6401 - val_accuracy: 0.5800\n",
      "Epoch 268/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6625 - val_loss: 0.6389 - val_accuracy: 0.5900\n",
      "Epoch 269/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6300 - val_loss: 0.6447 - val_accuracy: 0.5800\n",
      "Epoch 270/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6625 - val_loss: 0.6451 - val_accuracy: 0.5800\n",
      "Epoch 271/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.6550 - val_loss: 0.6469 - val_accuracy: 0.5900\n",
      "Epoch 272/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6475 - val_loss: 0.6474 - val_accuracy: 0.5800\n",
      "Epoch 273/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6375 - val_loss: 0.6418 - val_accuracy: 0.5700\n",
      "Epoch 274/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6525 - val_loss: 0.6397 - val_accuracy: 0.5700\n",
      "Epoch 275/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6475 - val_loss: 0.6467 - val_accuracy: 0.5700\n",
      "Epoch 276/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6375 - val_loss: 0.6514 - val_accuracy: 0.5800\n",
      "Epoch 277/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.6150 - val_loss: 0.6474 - val_accuracy: 0.5800\n",
      "Epoch 278/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6459 - accuracy: 0.6275 - val_loss: 0.6426 - val_accuracy: 0.5700\n",
      "Epoch 279/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6450 - val_loss: 0.6567 - val_accuracy: 0.5800\n",
      "Epoch 280/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6400 - val_loss: 0.6504 - val_accuracy: 0.5800\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6525 - val_loss: 0.6518 - val_accuracy: 0.5800\n",
      "Epoch 282/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.6250 - val_loss: 0.6501 - val_accuracy: 0.5600\n",
      "Epoch 283/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6550 - val_loss: 0.6427 - val_accuracy: 0.5800\n",
      "Epoch 284/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6344 - accuracy: 0.6425 - val_loss: 0.6411 - val_accuracy: 0.5800\n",
      "Epoch 285/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6500 - val_loss: 0.6413 - val_accuracy: 0.5800\n",
      "Epoch 286/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6425 - val_loss: 0.6534 - val_accuracy: 0.5700\n",
      "Epoch 287/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.6425 - val_loss: 0.6432 - val_accuracy: 0.5900\n",
      "Epoch 288/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6525 - val_loss: 0.6478 - val_accuracy: 0.5800\n",
      "Epoch 289/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6425 - val_loss: 0.6529 - val_accuracy: 0.5700\n",
      "Epoch 290/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6400 - val_loss: 0.6574 - val_accuracy: 0.5900\n",
      "Epoch 291/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6439 - accuracy: 0.6475 - val_loss: 0.6511 - val_accuracy: 0.5700\n",
      "Epoch 292/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6425 - val_loss: 0.6468 - val_accuracy: 0.5700\n",
      "Epoch 293/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6500 - val_loss: 0.6481 - val_accuracy: 0.5800\n",
      "Epoch 294/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6403 - accuracy: 0.6350 - val_loss: 0.6469 - val_accuracy: 0.5700\n",
      "Epoch 295/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6429 - accuracy: 0.6400 - val_loss: 0.6483 - val_accuracy: 0.5700\n",
      "Epoch 296/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6400 - accuracy: 0.6400 - val_loss: 0.6485 - val_accuracy: 0.5700\n",
      "Epoch 297/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6450 - val_loss: 0.6467 - val_accuracy: 0.5900\n",
      "Epoch 298/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6475 - val_loss: 0.6430 - val_accuracy: 0.5900\n",
      "Epoch 299/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6575 - val_loss: 0.6481 - val_accuracy: 0.5700\n",
      "Epoch 300/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6575 - val_loss: 0.6502 - val_accuracy: 0.5700\n",
      "Epoch 301/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6500 - val_loss: 0.6451 - val_accuracy: 0.5800\n",
      "Epoch 302/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6400 - val_loss: 0.6440 - val_accuracy: 0.5700\n",
      "Epoch 303/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6425 - val_loss: 0.6519 - val_accuracy: 0.5800\n",
      "Epoch 304/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6450 - val_loss: 0.6382 - val_accuracy: 0.5800\n",
      "Epoch 305/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6500 - val_loss: 0.6384 - val_accuracy: 0.5700\n",
      "Epoch 306/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.6550 - val_loss: 0.6400 - val_accuracy: 0.5800\n",
      "Epoch 307/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6391 - accuracy: 0.6350 - val_loss: 0.6403 - val_accuracy: 0.5800\n",
      "Epoch 308/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6256 - accuracy: 0.6475 - val_loss: 0.6466 - val_accuracy: 0.5700\n",
      "Epoch 309/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6250 - val_loss: 0.6362 - val_accuracy: 0.5800\n",
      "Epoch 310/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6400 - val_loss: 0.6404 - val_accuracy: 0.5800\n",
      "Epoch 311/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6425 - val_loss: 0.6538 - val_accuracy: 0.5800\n",
      "Epoch 312/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6450 - val_loss: 0.6501 - val_accuracy: 0.5800\n",
      "Epoch 313/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6600 - val_loss: 0.6504 - val_accuracy: 0.5600\n",
      "Epoch 314/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6375 - val_loss: 0.6601 - val_accuracy: 0.6000\n",
      "Epoch 315/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6375 - val_loss: 0.6588 - val_accuracy: 0.5800\n",
      "Epoch 316/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6600 - val_loss: 0.6690 - val_accuracy: 0.5600\n",
      "Epoch 317/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.6050 - val_loss: 0.6469 - val_accuracy: 0.5800\n",
      "Epoch 318/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6400 - val_loss: 0.6519 - val_accuracy: 0.5600\n",
      "Epoch 319/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6400 - val_loss: 0.6388 - val_accuracy: 0.5600\n",
      "Epoch 320/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6500 - val_loss: 0.6486 - val_accuracy: 0.5700\n",
      "Epoch 321/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6425 - val_loss: 0.6491 - val_accuracy: 0.5700\n",
      "Epoch 322/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.6450 - val_loss: 0.6513 - val_accuracy: 0.5700\n",
      "Epoch 323/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6500 - val_loss: 0.6478 - val_accuracy: 0.5600\n",
      "Epoch 324/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6525 - val_loss: 0.6664 - val_accuracy: 0.5700\n",
      "Epoch 325/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.6400 - val_loss: 0.6533 - val_accuracy: 0.5800\n",
      "Epoch 326/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6575 - val_loss: 0.6464 - val_accuracy: 0.5800\n",
      "Epoch 327/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6425 - val_loss: 0.6468 - val_accuracy: 0.5900\n",
      "Epoch 328/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.6500 - val_loss: 0.6470 - val_accuracy: 0.5900\n",
      "Epoch 329/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6550 - val_loss: 0.6464 - val_accuracy: 0.5700\n",
      "Epoch 330/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6410 - accuracy: 0.6325 - val_loss: 0.6358 - val_accuracy: 0.5900\n",
      "Epoch 331/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6500 - val_loss: 0.6569 - val_accuracy: 0.6000\n",
      "Epoch 332/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6450 - val_loss: 0.6523 - val_accuracy: 0.5800\n",
      "Epoch 333/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6397 - accuracy: 0.6475 - val_loss: 0.6562 - val_accuracy: 0.5700\n",
      "Epoch 334/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6450 - val_loss: 0.6530 - val_accuracy: 0.5800\n",
      "Epoch 335/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6500 - val_loss: 0.6525 - val_accuracy: 0.5700\n",
      "Epoch 336/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6300 - val_loss: 0.6639 - val_accuracy: 0.5700\n",
      "Epoch 337/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6375 - val_loss: 0.6628 - val_accuracy: 0.5800\n",
      "Epoch 338/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6500 - val_loss: 0.6610 - val_accuracy: 0.5800\n",
      "Epoch 339/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6450 - val_loss: 0.6525 - val_accuracy: 0.5800\n",
      "Epoch 340/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6425 - val_loss: 0.6535 - val_accuracy: 0.5900\n",
      "Epoch 341/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6487 - accuracy: 0.6350 - val_loss: 0.6567 - val_accuracy: 0.5800\n",
      "Epoch 342/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6230 - accuracy: 0.6325 - val_loss: 0.6436 - val_accuracy: 0.6000\n",
      "Epoch 343/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6450 - val_loss: 0.6466 - val_accuracy: 0.5700\n",
      "Epoch 344/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6251 - accuracy: 0.6625 - val_loss: 0.6490 - val_accuracy: 0.5900\n",
      "Epoch 345/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.6425 - val_loss: 0.6590 - val_accuracy: 0.5900\n",
      "Epoch 346/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6475 - val_loss: 0.6646 - val_accuracy: 0.5900\n",
      "Epoch 347/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6400 - val_loss: 0.6481 - val_accuracy: 0.6000\n",
      "Epoch 348/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6575 - val_loss: 0.6511 - val_accuracy: 0.6300\n",
      "Epoch 349/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.6275 - val_loss: 0.6399 - val_accuracy: 0.5900\n",
      "Epoch 350/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6575 - val_loss: 0.6363 - val_accuracy: 0.5800\n",
      "Epoch 351/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6525 - val_loss: 0.6471 - val_accuracy: 0.5900\n",
      "Epoch 352/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6475 - val_loss: 0.6456 - val_accuracy: 0.5800\n",
      "Epoch 353/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6290 - accuracy: 0.6275 - val_loss: 0.6320 - val_accuracy: 0.5800\n",
      "Epoch 354/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6425 - val_loss: 0.6417 - val_accuracy: 0.5800\n",
      "Epoch 355/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.6500 - val_loss: 0.6333 - val_accuracy: 0.5800\n",
      "Epoch 356/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6341 - accuracy: 0.6350 - val_loss: 0.6452 - val_accuracy: 0.5900\n",
      "Epoch 357/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6385 - accuracy: 0.6250 - val_loss: 0.6509 - val_accuracy: 0.5800\n",
      "Epoch 358/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6343 - accuracy: 0.6375 - val_loss: 0.6455 - val_accuracy: 0.5700\n",
      "Epoch 359/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.6500 - val_loss: 0.6450 - val_accuracy: 0.5800\n",
      "Epoch 360/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.6700 - val_loss: 0.6468 - val_accuracy: 0.5800\n",
      "Epoch 361/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6414 - accuracy: 0.6525 - val_loss: 0.6357 - val_accuracy: 0.5700\n",
      "Epoch 362/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6400 - val_loss: 0.6415 - val_accuracy: 0.5900\n",
      "Epoch 363/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6425 - val_loss: 0.6438 - val_accuracy: 0.5900\n",
      "Epoch 364/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6475 - val_loss: 0.6726 - val_accuracy: 0.6100\n",
      "Epoch 365/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.6450 - val_loss: 0.6349 - val_accuracy: 0.5900\n",
      "Epoch 366/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6225 - val_loss: 0.6348 - val_accuracy: 0.5900\n",
      "Epoch 367/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.6100 - val_loss: 0.6389 - val_accuracy: 0.5900\n",
      "Epoch 368/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6350 - val_loss: 0.6287 - val_accuracy: 0.5800\n",
      "Epoch 369/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6575 - val_loss: 0.6356 - val_accuracy: 0.6000\n",
      "Epoch 370/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.6600 - val_loss: 0.6386 - val_accuracy: 0.6000\n",
      "Epoch 371/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6266 - accuracy: 0.6450 - val_loss: 0.6352 - val_accuracy: 0.5900\n",
      "Epoch 372/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6725 - val_loss: 0.6414 - val_accuracy: 0.5900\n",
      "Epoch 373/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6190 - accuracy: 0.6725 - val_loss: 0.6406 - val_accuracy: 0.6100\n",
      "Epoch 374/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6425 - val_loss: 0.6368 - val_accuracy: 0.6100\n",
      "Epoch 375/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6375 - val_loss: 0.6449 - val_accuracy: 0.6100\n",
      "Epoch 376/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6500 - val_loss: 0.6412 - val_accuracy: 0.5900\n",
      "Epoch 377/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.6550 - val_loss: 0.6528 - val_accuracy: 0.6000\n",
      "Epoch 378/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6550 - val_loss: 0.6460 - val_accuracy: 0.5900\n",
      "Epoch 379/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6375 - val_loss: 0.6493 - val_accuracy: 0.6000\n",
      "Epoch 380/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6675 - val_loss: 0.6607 - val_accuracy: 0.6100\n",
      "Epoch 381/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6600 - val_loss: 0.6447 - val_accuracy: 0.6200\n",
      "Epoch 382/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6330 - accuracy: 0.6350 - val_loss: 0.6416 - val_accuracy: 0.6200\n",
      "Epoch 383/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6525 - val_loss: 0.6490 - val_accuracy: 0.5900\n",
      "Epoch 384/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6525 - val_loss: 0.6521 - val_accuracy: 0.6200\n",
      "Epoch 385/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6475 - val_loss: 0.6484 - val_accuracy: 0.6100\n",
      "Epoch 386/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.6525 - val_loss: 0.6504 - val_accuracy: 0.5900\n",
      "Epoch 387/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6625 - val_loss: 0.6488 - val_accuracy: 0.6000\n",
      "Epoch 388/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6400 - val_loss: 0.6489 - val_accuracy: 0.5900\n",
      "Epoch 389/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.6425 - val_loss: 0.6362 - val_accuracy: 0.6000\n",
      "Epoch 390/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6525 - val_loss: 0.6407 - val_accuracy: 0.5800\n",
      "Epoch 391/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6265 - accuracy: 0.6525 - val_loss: 0.6434 - val_accuracy: 0.5900\n",
      "Epoch 392/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6700 - val_loss: 0.6531 - val_accuracy: 0.6100\n",
      "Epoch 393/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6254 - accuracy: 0.6625 - val_loss: 0.6591 - val_accuracy: 0.6000\n",
      "Epoch 394/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6550 - val_loss: 0.6542 - val_accuracy: 0.6000\n",
      "Epoch 395/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6625 - val_loss: 0.6511 - val_accuracy: 0.6100\n",
      "Epoch 396/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6525 - val_loss: 0.6499 - val_accuracy: 0.6100\n",
      "Epoch 397/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6500 - val_loss: 0.6597 - val_accuracy: 0.6100\n",
      "Epoch 398/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6273 - accuracy: 0.6675 - val_loss: 0.6505 - val_accuracy: 0.5900\n",
      "Epoch 399/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.6625 - val_loss: 0.6550 - val_accuracy: 0.6000\n",
      "Epoch 400/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.6600 - val_loss: 0.6592 - val_accuracy: 0.5900\n",
      "Epoch 401/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.6575 - val_loss: 0.6750 - val_accuracy: 0.5900\n",
      "Epoch 402/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6550 - val_loss: 0.6506 - val_accuracy: 0.5800\n",
      "Epoch 403/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.6500 - val_loss: 0.6530 - val_accuracy: 0.5600\n",
      "Epoch 404/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6600 - val_loss: 0.6557 - val_accuracy: 0.5900\n",
      "Epoch 405/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6348 - accuracy: 0.6400 - val_loss: 0.6552 - val_accuracy: 0.5900\n",
      "Epoch 406/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6525 - val_loss: 0.6430 - val_accuracy: 0.5900\n",
      "Epoch 407/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.6475 - val_loss: 0.6458 - val_accuracy: 0.5700\n",
      "Epoch 408/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6199 - accuracy: 0.6575 - val_loss: 0.6535 - val_accuracy: 0.5900\n",
      "Epoch 409/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.6575 - val_loss: 0.6447 - val_accuracy: 0.5900\n",
      "Epoch 410/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6375 - val_loss: 0.6396 - val_accuracy: 0.5800\n",
      "Epoch 411/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6317 - accuracy: 0.6525 - val_loss: 0.6505 - val_accuracy: 0.5700\n",
      "Epoch 412/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6475 - val_loss: 0.6580 - val_accuracy: 0.5900\n",
      "Epoch 413/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6450 - val_loss: 0.6534 - val_accuracy: 0.5900\n",
      "Epoch 414/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6500 - val_loss: 0.6451 - val_accuracy: 0.6000\n",
      "Epoch 415/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6189 - accuracy: 0.6775 - val_loss: 0.6460 - val_accuracy: 0.6000\n",
      "Epoch 416/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.6575 - val_loss: 0.6449 - val_accuracy: 0.6000\n",
      "Epoch 417/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6650 - val_loss: 0.6439 - val_accuracy: 0.5800\n",
      "Epoch 418/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6700 - val_loss: 0.6358 - val_accuracy: 0.6000\n",
      "Epoch 419/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6475 - val_loss: 0.6450 - val_accuracy: 0.6000\n",
      "Epoch 420/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6402 - accuracy: 0.6550 - val_loss: 0.6368 - val_accuracy: 0.5900\n",
      "Epoch 421/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6325 - val_loss: 0.6390 - val_accuracy: 0.5900\n",
      "Epoch 422/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6550 - val_loss: 0.6356 - val_accuracy: 0.5800\n",
      "Epoch 423/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6625 - val_loss: 0.6378 - val_accuracy: 0.5900\n",
      "Epoch 424/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.6500 - val_loss: 0.6435 - val_accuracy: 0.5900\n",
      "Epoch 425/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6211 - accuracy: 0.6725 - val_loss: 0.6395 - val_accuracy: 0.5800\n",
      "Epoch 426/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6550 - val_loss: 0.6385 - val_accuracy: 0.5800\n",
      "Epoch 427/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.6675 - val_loss: 0.6453 - val_accuracy: 0.5900\n",
      "Epoch 428/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6675 - val_loss: 0.6399 - val_accuracy: 0.5800\n",
      "Epoch 429/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6300 - val_loss: 0.6273 - val_accuracy: 0.6000\n",
      "Epoch 430/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6725 - val_loss: 0.6369 - val_accuracy: 0.5900\n",
      "Epoch 431/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6367 - accuracy: 0.6625 - val_loss: 0.6241 - val_accuracy: 0.6000\n",
      "Epoch 432/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.6750 - val_loss: 0.6485 - val_accuracy: 0.5700\n",
      "Epoch 433/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6161 - accuracy: 0.6550 - val_loss: 0.6420 - val_accuracy: 0.5900\n",
      "Epoch 434/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6750 - val_loss: 0.6503 - val_accuracy: 0.5900\n",
      "Epoch 435/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.6600 - val_loss: 0.6459 - val_accuracy: 0.5800\n",
      "Epoch 436/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.6425 - val_loss: 0.6327 - val_accuracy: 0.5800\n",
      "Epoch 437/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6650 - val_loss: 0.6492 - val_accuracy: 0.5900\n",
      "Epoch 438/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6262 - accuracy: 0.6600 - val_loss: 0.6473 - val_accuracy: 0.5900\n",
      "Epoch 439/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6500 - val_loss: 0.6732 - val_accuracy: 0.5900\n",
      "Epoch 440/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.6450 - val_loss: 0.6495 - val_accuracy: 0.5900\n",
      "Epoch 441/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6513 - val_accuracy: 0.5900\n",
      "Epoch 442/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.6625 - val_loss: 0.6400 - val_accuracy: 0.5800\n",
      "Epoch 443/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.6450 - val_loss: 0.6430 - val_accuracy: 0.5800\n",
      "Epoch 444/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.6425 - val_loss: 0.6560 - val_accuracy: 0.5700\n",
      "Epoch 445/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6197 - accuracy: 0.6625 - val_loss: 0.6479 - val_accuracy: 0.5600\n",
      "Epoch 446/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6475 - val_loss: 0.6379 - val_accuracy: 0.5900\n",
      "Epoch 447/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.6725 - val_loss: 0.6335 - val_accuracy: 0.5900\n",
      "Epoch 448/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.6175 - val_loss: 0.6360 - val_accuracy: 0.6000\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.6600 - val_loss: 0.7106 - val_accuracy: 0.6000\n",
      "Epoch 450/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6650 - val_loss: 0.6534 - val_accuracy: 0.6000\n",
      "Epoch 451/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6194 - accuracy: 0.6625 - val_loss: 0.6552 - val_accuracy: 0.5900\n",
      "Epoch 452/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.6700 - val_loss: 0.6462 - val_accuracy: 0.5900\n",
      "Epoch 453/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6700 - val_loss: 0.6549 - val_accuracy: 0.5900\n",
      "Epoch 454/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.6450 - val_loss: 0.6377 - val_accuracy: 0.6100\n",
      "Epoch 455/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6550 - val_loss: 0.6438 - val_accuracy: 0.5700\n",
      "Epoch 456/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6700 - val_loss: 0.6459 - val_accuracy: 0.5900\n",
      "Epoch 457/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6500 - val_loss: 0.6518 - val_accuracy: 0.5800\n",
      "Epoch 458/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6575 - val_loss: 0.6488 - val_accuracy: 0.5700\n",
      "Epoch 459/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6650 - val_loss: 0.6392 - val_accuracy: 0.5700\n",
      "Epoch 460/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.6475 - val_loss: 0.6474 - val_accuracy: 0.5900\n",
      "Epoch 461/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6675 - val_loss: 0.6398 - val_accuracy: 0.5800\n",
      "Epoch 462/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6257 - accuracy: 0.6425 - val_loss: 0.6405 - val_accuracy: 0.5900\n",
      "Epoch 463/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6550 - val_loss: 0.6513 - val_accuracy: 0.6100\n",
      "Epoch 464/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6233 - accuracy: 0.6575 - val_loss: 0.6560 - val_accuracy: 0.6200\n",
      "Epoch 465/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6267 - accuracy: 0.6525 - val_loss: 0.6583 - val_accuracy: 0.5900\n",
      "Epoch 466/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.6825 - val_loss: 0.6627 - val_accuracy: 0.5800\n",
      "Epoch 467/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6213 - accuracy: 0.6675 - val_loss: 0.6571 - val_accuracy: 0.6000\n",
      "Epoch 468/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6278 - accuracy: 0.6575 - val_loss: 0.6467 - val_accuracy: 0.6100\n",
      "Epoch 469/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6550 - val_loss: 0.6518 - val_accuracy: 0.5700\n",
      "Epoch 470/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6650 - val_loss: 0.6623 - val_accuracy: 0.6100\n",
      "Epoch 471/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6228 - accuracy: 0.6725 - val_loss: 0.6824 - val_accuracy: 0.6000\n",
      "Epoch 472/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6700 - val_loss: 0.6416 - val_accuracy: 0.6000\n",
      "Epoch 473/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.6600 - val_loss: 0.6503 - val_accuracy: 0.6100\n",
      "Epoch 474/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6145 - accuracy: 0.6775 - val_loss: 0.6433 - val_accuracy: 0.6100\n",
      "Epoch 475/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.6650 - val_loss: 0.6486 - val_accuracy: 0.6000\n",
      "Epoch 476/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6725 - val_loss: 0.6455 - val_accuracy: 0.6100\n",
      "Epoch 477/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6725 - val_loss: 0.6528 - val_accuracy: 0.6200\n",
      "Epoch 478/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6157 - accuracy: 0.6725 - val_loss: 0.6458 - val_accuracy: 0.6000\n",
      "Epoch 479/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.6675 - val_loss: 0.6469 - val_accuracy: 0.6100\n",
      "Epoch 480/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6575 - val_loss: 0.6335 - val_accuracy: 0.6000\n",
      "Epoch 481/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6217 - accuracy: 0.6525 - val_loss: 0.6444 - val_accuracy: 0.6000\n",
      "Epoch 482/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6525 - val_loss: 0.6507 - val_accuracy: 0.5900\n",
      "Epoch 483/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6775 - val_loss: 0.6421 - val_accuracy: 0.5900\n",
      "Epoch 484/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6650 - val_loss: 0.6423 - val_accuracy: 0.6000\n",
      "Epoch 485/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6550 - val_loss: 0.6404 - val_accuracy: 0.5900\n",
      "Epoch 486/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.6625 - val_loss: 0.6362 - val_accuracy: 0.6100\n",
      "Epoch 487/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6550 - val_loss: 0.6366 - val_accuracy: 0.5900\n",
      "Epoch 488/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6149 - accuracy: 0.6625 - val_loss: 0.6423 - val_accuracy: 0.6100\n",
      "Epoch 489/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.6750 - val_loss: 0.6322 - val_accuracy: 0.6000\n",
      "Epoch 490/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6750 - val_loss: 0.6364 - val_accuracy: 0.6300\n",
      "Epoch 491/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6675 - val_loss: 0.6452 - val_accuracy: 0.5900\n",
      "Epoch 492/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6675 - val_loss: 0.6486 - val_accuracy: 0.5900\n",
      "Epoch 493/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.6575 - val_loss: 0.6444 - val_accuracy: 0.6000\n",
      "Epoch 494/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.6700 - val_loss: 0.6541 - val_accuracy: 0.6300\n",
      "Epoch 495/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6675 - val_loss: 0.6422 - val_accuracy: 0.6300\n",
      "Epoch 496/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.6875 - val_loss: 0.6351 - val_accuracy: 0.6000\n",
      "Epoch 497/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6700 - val_loss: 0.6418 - val_accuracy: 0.5800\n",
      "Epoch 498/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.6750 - val_loss: 0.6413 - val_accuracy: 0.5800\n",
      "Epoch 499/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6166 - accuracy: 0.6725 - val_loss: 0.6518 - val_accuracy: 0.6200\n",
      "Epoch 500/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6236 - accuracy: 0.6650 - val_loss: 0.6501 - val_accuracy: 0.6000\n",
      "Epoch 501/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6900 - val_loss: 0.6536 - val_accuracy: 0.6200\n",
      "Epoch 502/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6173 - accuracy: 0.6725 - val_loss: 0.6445 - val_accuracy: 0.5900\n",
      "Epoch 503/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6158 - accuracy: 0.6650 - val_loss: 0.6404 - val_accuracy: 0.6100\n",
      "Epoch 504/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6650 - val_loss: 0.6628 - val_accuracy: 0.6000\n",
      "Epoch 505/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.6500 - val_loss: 0.6274 - val_accuracy: 0.6100\n",
      "Epoch 506/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6056 - accuracy: 0.6700 - val_loss: 0.6306 - val_accuracy: 0.6200\n",
      "Epoch 507/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6850 - val_loss: 0.6489 - val_accuracy: 0.6100\n",
      "Epoch 508/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6319 - accuracy: 0.6625 - val_loss: 0.6568 - val_accuracy: 0.6200\n",
      "Epoch 509/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6105 - accuracy: 0.6650 - val_loss: 0.6390 - val_accuracy: 0.6300\n",
      "Epoch 510/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6131 - accuracy: 0.6750 - val_loss: 0.6478 - val_accuracy: 0.6300\n",
      "Epoch 511/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6550 - val_loss: 0.6582 - val_accuracy: 0.6200\n",
      "Epoch 512/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6900 - val_loss: 0.6405 - val_accuracy: 0.6100\n",
      "Epoch 513/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6725 - val_loss: 0.6562 - val_accuracy: 0.6100\n",
      "Epoch 514/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.6800 - val_loss: 0.6292 - val_accuracy: 0.6300\n",
      "Epoch 515/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6245 - accuracy: 0.6775 - val_loss: 0.6317 - val_accuracy: 0.6400\n",
      "Epoch 516/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6775 - val_loss: 0.6344 - val_accuracy: 0.5900\n",
      "Epoch 517/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6093 - accuracy: 0.6725 - val_loss: 0.6834 - val_accuracy: 0.6100\n",
      "Epoch 518/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6800 - val_loss: 0.6299 - val_accuracy: 0.6200\n",
      "Epoch 519/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6182 - accuracy: 0.6750 - val_loss: 0.6279 - val_accuracy: 0.6200\n",
      "Epoch 520/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6600 - val_loss: 0.6252 - val_accuracy: 0.6400\n",
      "Epoch 521/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6675 - val_loss: 0.6329 - val_accuracy: 0.6000\n",
      "Epoch 522/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.6725 - val_loss: 0.6370 - val_accuracy: 0.6000\n",
      "Epoch 523/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6850 - val_loss: 0.6403 - val_accuracy: 0.6200\n",
      "Epoch 524/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6600 - val_loss: 0.6331 - val_accuracy: 0.6000\n",
      "Epoch 525/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6750 - val_loss: 0.6566 - val_accuracy: 0.5900\n",
      "Epoch 526/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5960 - accuracy: 0.6800 - val_loss: 0.6445 - val_accuracy: 0.6300\n",
      "Epoch 527/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6825 - val_loss: 0.6479 - val_accuracy: 0.6200\n",
      "Epoch 528/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6800 - val_loss: 0.6523 - val_accuracy: 0.5900\n",
      "Epoch 529/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6875 - val_loss: 0.6613 - val_accuracy: 0.5800\n",
      "Epoch 530/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.6625 - val_loss: 0.6485 - val_accuracy: 0.6100\n",
      "Epoch 531/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.6825 - val_loss: 0.6906 - val_accuracy: 0.6200\n",
      "Epoch 532/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6095 - accuracy: 0.6725 - val_loss: 0.6422 - val_accuracy: 0.6300\n",
      "Epoch 533/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6042 - accuracy: 0.6750 - val_loss: 0.6575 - val_accuracy: 0.6200\n",
      "Epoch 534/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.6850 - val_loss: 0.6582 - val_accuracy: 0.6200\n",
      "Epoch 535/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6725 - val_loss: 0.6514 - val_accuracy: 0.6100\n",
      "Epoch 536/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6750 - val_loss: 0.6546 - val_accuracy: 0.5900\n",
      "Epoch 537/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.6700 - val_loss: 0.6506 - val_accuracy: 0.6200\n",
      "Epoch 538/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6026 - accuracy: 0.6875 - val_loss: 0.6498 - val_accuracy: 0.5800\n",
      "Epoch 539/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6107 - accuracy: 0.6775 - val_loss: 0.6461 - val_accuracy: 0.6100\n",
      "Epoch 540/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6650 - val_loss: 0.6398 - val_accuracy: 0.6200\n",
      "Epoch 541/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6234 - accuracy: 0.6575 - val_loss: 0.6373 - val_accuracy: 0.6000\n",
      "Epoch 542/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6600 - val_loss: 0.6346 - val_accuracy: 0.6200\n",
      "Epoch 543/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6650 - val_loss: 0.6392 - val_accuracy: 0.6200\n",
      "Epoch 544/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6750 - val_loss: 0.6547 - val_accuracy: 0.6300\n",
      "Epoch 545/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6850 - val_loss: 0.6516 - val_accuracy: 0.6300\n",
      "Epoch 546/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6825 - val_loss: 0.6538 - val_accuracy: 0.6100\n",
      "Epoch 547/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6132 - accuracy: 0.6800 - val_loss: 0.6467 - val_accuracy: 0.6100\n",
      "Epoch 548/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6575 - val_loss: 0.6503 - val_accuracy: 0.6000\n",
      "Epoch 549/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6116 - accuracy: 0.6725 - val_loss: 0.6300 - val_accuracy: 0.6400\n",
      "Epoch 550/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6750 - val_loss: 0.6348 - val_accuracy: 0.6400\n",
      "Epoch 551/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6675 - val_loss: 0.6379 - val_accuracy: 0.6500\n",
      "Epoch 552/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6525 - val_loss: 0.6579 - val_accuracy: 0.6200\n",
      "Epoch 553/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.6575 - val_loss: 0.6454 - val_accuracy: 0.6300\n",
      "Epoch 554/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.6750 - val_loss: 0.6517 - val_accuracy: 0.6300\n",
      "Epoch 555/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6318 - accuracy: 0.6525 - val_loss: 0.6366 - val_accuracy: 0.6500\n",
      "Epoch 556/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6061 - accuracy: 0.6825 - val_loss: 0.6403 - val_accuracy: 0.6200\n",
      "Epoch 557/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6825 - val_loss: 0.6348 - val_accuracy: 0.6400\n",
      "Epoch 558/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6925 - val_loss: 0.6414 - val_accuracy: 0.6300\n",
      "Epoch 559/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6052 - accuracy: 0.6800 - val_loss: 0.6461 - val_accuracy: 0.6300\n",
      "Epoch 560/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6625 - val_loss: 0.6610 - val_accuracy: 0.6200\n",
      "Epoch 561/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6625 - val_loss: 0.6523 - val_accuracy: 0.6100\n",
      "Epoch 562/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6875 - val_loss: 0.6480 - val_accuracy: 0.6300\n",
      "Epoch 563/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6009 - accuracy: 0.6875 - val_loss: 0.6603 - val_accuracy: 0.6000\n",
      "Epoch 564/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6140 - accuracy: 0.6725 - val_loss: 0.6563 - val_accuracy: 0.6100\n",
      "Epoch 565/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.6650 - val_loss: 0.6451 - val_accuracy: 0.6200\n",
      "Epoch 566/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6044 - accuracy: 0.6725 - val_loss: 0.6450 - val_accuracy: 0.6300\n",
      "Epoch 567/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6825 - val_loss: 0.6580 - val_accuracy: 0.6300\n",
      "Epoch 568/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6800 - val_loss: 0.6586 - val_accuracy: 0.6200\n",
      "Epoch 569/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.6725 - val_loss: 0.6557 - val_accuracy: 0.6100\n",
      "Epoch 570/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6625 - val_loss: 0.6473 - val_accuracy: 0.6000\n",
      "Epoch 571/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6825 - val_loss: 0.6438 - val_accuracy: 0.6200\n",
      "Epoch 572/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6725 - val_loss: 0.6431 - val_accuracy: 0.6100\n",
      "Epoch 573/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6750 - val_loss: 0.6543 - val_accuracy: 0.6100\n",
      "Epoch 574/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6650 - val_loss: 0.6426 - val_accuracy: 0.6300\n",
      "Epoch 575/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.6575 - val_loss: 0.6358 - val_accuracy: 0.6300\n",
      "Epoch 576/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6800 - val_loss: 0.6594 - val_accuracy: 0.6100\n",
      "Epoch 577/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6800 - val_loss: 0.6589 - val_accuracy: 0.6000\n",
      "Epoch 578/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5977 - accuracy: 0.6750 - val_loss: 0.6642 - val_accuracy: 0.6200\n",
      "Epoch 579/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6725 - val_loss: 0.6584 - val_accuracy: 0.6200\n",
      "Epoch 580/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6024 - accuracy: 0.6725 - val_loss: 0.6501 - val_accuracy: 0.6000\n",
      "Epoch 581/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6212 - accuracy: 0.6625 - val_loss: 0.6481 - val_accuracy: 0.6300\n",
      "Epoch 582/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6950 - val_loss: 0.6504 - val_accuracy: 0.6200\n",
      "Epoch 583/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6092 - accuracy: 0.6800 - val_loss: 0.6588 - val_accuracy: 0.6200\n",
      "Epoch 584/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6725 - val_loss: 0.6476 - val_accuracy: 0.6400\n",
      "Epoch 585/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6146 - accuracy: 0.6825 - val_loss: 0.6432 - val_accuracy: 0.6500\n",
      "Epoch 586/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6106 - accuracy: 0.6750 - val_loss: 0.6531 - val_accuracy: 0.6300\n",
      "Epoch 587/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6099 - accuracy: 0.6725 - val_loss: 0.6643 - val_accuracy: 0.6100\n",
      "Epoch 588/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6800 - val_loss: 0.6557 - val_accuracy: 0.6000\n",
      "Epoch 589/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6138 - accuracy: 0.6650 - val_loss: 0.6556 - val_accuracy: 0.6200\n",
      "Epoch 590/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6035 - accuracy: 0.6875 - val_loss: 0.6549 - val_accuracy: 0.6100\n",
      "Epoch 591/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6800 - val_loss: 0.6480 - val_accuracy: 0.6400\n",
      "Epoch 592/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6008 - accuracy: 0.6675 - val_loss: 0.6542 - val_accuracy: 0.6100\n",
      "Epoch 593/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5889 - accuracy: 0.6875 - val_loss: 0.6625 - val_accuracy: 0.6200\n",
      "Epoch 594/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6775 - val_loss: 0.6573 - val_accuracy: 0.6200\n",
      "Epoch 595/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6124 - accuracy: 0.6700 - val_loss: 0.6503 - val_accuracy: 0.6200\n",
      "Epoch 596/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6117 - accuracy: 0.6800 - val_loss: 0.6480 - val_accuracy: 0.6200\n",
      "Epoch 597/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6750 - val_loss: 0.6569 - val_accuracy: 0.6100\n",
      "Epoch 598/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6064 - accuracy: 0.6650 - val_loss: 0.6670 - val_accuracy: 0.6200\n",
      "Epoch 599/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5956 - accuracy: 0.7025 - val_loss: 0.6694 - val_accuracy: 0.6100\n",
      "Epoch 600/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6010 - accuracy: 0.6900 - val_loss: 0.6568 - val_accuracy: 0.6200\n",
      "Epoch 601/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6775 - val_loss: 0.6506 - val_accuracy: 0.6100\n",
      "Epoch 602/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6600 - val_loss: 0.6544 - val_accuracy: 0.6000\n",
      "Epoch 603/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6130 - accuracy: 0.6950 - val_loss: 0.6665 - val_accuracy: 0.5900\n",
      "Epoch 604/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.6800 - val_loss: 0.6572 - val_accuracy: 0.6100\n",
      "Epoch 605/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.6700 - val_loss: 0.6518 - val_accuracy: 0.5900\n",
      "Epoch 606/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6850 - val_loss: 0.6510 - val_accuracy: 0.6400\n",
      "Epoch 607/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.6850 - val_loss: 0.6600 - val_accuracy: 0.6300\n",
      "Epoch 608/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6600 - val_loss: 0.6592 - val_accuracy: 0.6200\n",
      "Epoch 609/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6020 - accuracy: 0.6825 - val_loss: 0.6732 - val_accuracy: 0.6100\n",
      "Epoch 610/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6725 - val_loss: 0.6575 - val_accuracy: 0.6200\n",
      "Epoch 611/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5997 - accuracy: 0.6750 - val_loss: 0.6567 - val_accuracy: 0.6100\n",
      "Epoch 612/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6069 - accuracy: 0.6650 - val_loss: 0.6467 - val_accuracy: 0.6400\n",
      "Epoch 613/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6775 - val_loss: 0.6625 - val_accuracy: 0.6100\n",
      "Epoch 614/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6022 - accuracy: 0.6775 - val_loss: 0.6515 - val_accuracy: 0.6400\n",
      "Epoch 615/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.6875 - val_loss: 0.6535 - val_accuracy: 0.6200\n",
      "Epoch 616/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6030 - accuracy: 0.6950 - val_loss: 0.6527 - val_accuracy: 0.6000\n",
      "Epoch 617/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.6825 - val_loss: 0.6560 - val_accuracy: 0.6300\n",
      "Epoch 618/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6575 - val_loss: 0.6608 - val_accuracy: 0.6100\n",
      "Epoch 619/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.6750 - val_loss: 0.6399 - val_accuracy: 0.5900\n",
      "Epoch 620/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6041 - accuracy: 0.6825 - val_loss: 0.6516 - val_accuracy: 0.6000\n",
      "Epoch 621/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6108 - accuracy: 0.6625 - val_loss: 0.6600 - val_accuracy: 0.6200\n",
      "Epoch 622/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6025 - accuracy: 0.6725 - val_loss: 0.6593 - val_accuracy: 0.5800\n",
      "Epoch 623/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.6900 - val_loss: 0.6684 - val_accuracy: 0.5900\n",
      "Epoch 624/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6950 - val_loss: 0.6669 - val_accuracy: 0.6100\n",
      "Epoch 625/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6950 - val_loss: 0.6737 - val_accuracy: 0.5700\n",
      "Epoch 626/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6750 - val_loss: 0.6764 - val_accuracy: 0.5800\n",
      "Epoch 627/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6058 - accuracy: 0.6800 - val_loss: 0.6813 - val_accuracy: 0.5900\n",
      "Epoch 628/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6850 - val_loss: 0.6718 - val_accuracy: 0.6200\n",
      "Epoch 629/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.6850 - val_loss: 0.6749 - val_accuracy: 0.6000\n",
      "Epoch 630/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6015 - accuracy: 0.6825 - val_loss: 0.6679 - val_accuracy: 0.5900\n",
      "Epoch 631/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6625 - val_loss: 0.6716 - val_accuracy: 0.6200\n",
      "Epoch 632/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6775 - val_loss: 0.6837 - val_accuracy: 0.5800\n",
      "Epoch 633/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.6600 - val_loss: 0.6840 - val_accuracy: 0.5800\n",
      "Epoch 634/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6101 - accuracy: 0.7000 - val_loss: 0.6713 - val_accuracy: 0.5900\n",
      "Epoch 635/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.6925 - val_loss: 0.6724 - val_accuracy: 0.5600\n",
      "Epoch 636/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6850 - val_loss: 0.6630 - val_accuracy: 0.6000\n",
      "Epoch 637/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.6550 - val_loss: 0.6569 - val_accuracy: 0.6200\n",
      "Epoch 638/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6750 - val_loss: 0.6602 - val_accuracy: 0.6200\n",
      "Epoch 639/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6014 - accuracy: 0.6700 - val_loss: 0.6719 - val_accuracy: 0.6200\n",
      "Epoch 640/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.6950 - val_loss: 0.6689 - val_accuracy: 0.6100\n",
      "Epoch 641/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6750 - val_loss: 0.6692 - val_accuracy: 0.6200\n",
      "Epoch 642/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6950 - val_loss: 0.6613 - val_accuracy: 0.6400\n",
      "Epoch 643/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6925 - val_loss: 0.6810 - val_accuracy: 0.5900\n",
      "Epoch 644/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6950 - val_loss: 0.6689 - val_accuracy: 0.6000\n",
      "Epoch 645/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6825 - val_loss: 0.6561 - val_accuracy: 0.6200\n",
      "Epoch 646/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.6550 - val_loss: 0.6706 - val_accuracy: 0.6500\n",
      "Epoch 647/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6775 - val_loss: 0.6508 - val_accuracy: 0.6200\n",
      "Epoch 648/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6825 - val_loss: 0.6487 - val_accuracy: 0.6400\n",
      "Epoch 649/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5999 - accuracy: 0.6725 - val_loss: 0.6495 - val_accuracy: 0.6400\n",
      "Epoch 650/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6011 - accuracy: 0.6900 - val_loss: 0.6446 - val_accuracy: 0.6400\n",
      "Epoch 651/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6800 - val_loss: 0.6387 - val_accuracy: 0.6400\n",
      "Epoch 652/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6850 - val_loss: 0.6530 - val_accuracy: 0.6300\n",
      "Epoch 653/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6775 - val_loss: 0.6512 - val_accuracy: 0.6100\n",
      "Epoch 654/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.6700 - val_loss: 0.6498 - val_accuracy: 0.6200\n",
      "Epoch 655/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.7100 - val_loss: 0.6645 - val_accuracy: 0.6000\n",
      "Epoch 656/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6076 - accuracy: 0.6675 - val_loss: 0.6545 - val_accuracy: 0.6300\n",
      "Epoch 657/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6875 - val_loss: 0.6544 - val_accuracy: 0.6300\n",
      "Epoch 658/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6104 - accuracy: 0.6850 - val_loss: 0.6513 - val_accuracy: 0.6300\n",
      "Epoch 659/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5993 - accuracy: 0.6900 - val_loss: 0.6536 - val_accuracy: 0.6100\n",
      "Epoch 660/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.6650 - val_loss: 0.6499 - val_accuracy: 0.6300\n",
      "Epoch 661/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6925 - val_loss: 0.6489 - val_accuracy: 0.6200\n",
      "Epoch 662/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6089 - accuracy: 0.7125 - val_loss: 0.6685 - val_accuracy: 0.6100\n",
      "Epoch 663/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5995 - accuracy: 0.6725 - val_loss: 0.6638 - val_accuracy: 0.6200\n",
      "Epoch 664/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6023 - accuracy: 0.6700 - val_loss: 0.6581 - val_accuracy: 0.6000\n",
      "Epoch 665/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.6875 - val_loss: 0.6554 - val_accuracy: 0.6200\n",
      "Epoch 666/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6750 - val_loss: 0.6712 - val_accuracy: 0.6300\n",
      "Epoch 667/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.7025 - val_loss: 0.6665 - val_accuracy: 0.6000\n",
      "Epoch 668/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6775 - val_loss: 0.6677 - val_accuracy: 0.6200\n",
      "Epoch 669/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.6700 - val_loss: 0.6596 - val_accuracy: 0.6200\n",
      "Epoch 670/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6875 - val_loss: 0.6639 - val_accuracy: 0.6100\n",
      "Epoch 671/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5973 - accuracy: 0.6800 - val_loss: 0.6632 - val_accuracy: 0.6200\n",
      "Epoch 672/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6269 - accuracy: 0.6625 - val_loss: 0.6578 - val_accuracy: 0.6200\n",
      "Epoch 673/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6725 - val_loss: 0.6587 - val_accuracy: 0.6200\n",
      "Epoch 674/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5941 - accuracy: 0.6800 - val_loss: 0.6671 - val_accuracy: 0.6000\n",
      "Epoch 675/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5976 - accuracy: 0.6975 - val_loss: 0.6717 - val_accuracy: 0.6100\n",
      "Epoch 676/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6775 - val_loss: 0.6850 - val_accuracy: 0.6000\n",
      "Epoch 677/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.6775 - val_loss: 0.6846 - val_accuracy: 0.6100\n",
      "Epoch 678/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6085 - accuracy: 0.6800 - val_loss: 0.6865 - val_accuracy: 0.6000\n",
      "Epoch 679/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6090 - accuracy: 0.6800 - val_loss: 0.6646 - val_accuracy: 0.6000\n",
      "Epoch 680/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5958 - accuracy: 0.6700 - val_loss: 0.6645 - val_accuracy: 0.6100\n",
      "Epoch 681/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5981 - accuracy: 0.6950 - val_loss: 0.6663 - val_accuracy: 0.6200\n",
      "Epoch 682/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5725 - accuracy: 0.7000 - val_loss: 0.6742 - val_accuracy: 0.6100\n",
      "Epoch 683/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6875 - val_loss: 0.6871 - val_accuracy: 0.6000\n",
      "Epoch 684/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6625 - val_loss: 0.6709 - val_accuracy: 0.5900\n",
      "Epoch 685/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.6725 - val_loss: 0.6534 - val_accuracy: 0.6200\n",
      "Epoch 686/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6087 - accuracy: 0.6700 - val_loss: 0.6589 - val_accuracy: 0.6100\n",
      "Epoch 687/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6775 - val_loss: 0.6622 - val_accuracy: 0.6200\n",
      "Epoch 688/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6850 - val_loss: 0.6486 - val_accuracy: 0.6100\n",
      "Epoch 689/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.6750 - val_loss: 0.6681 - val_accuracy: 0.6200\n",
      "Epoch 690/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5997 - accuracy: 0.6725 - val_loss: 0.6701 - val_accuracy: 0.6000\n",
      "Epoch 691/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6055 - accuracy: 0.6750 - val_loss: 0.6658 - val_accuracy: 0.6100\n",
      "Epoch 692/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6750 - val_loss: 0.6601 - val_accuracy: 0.6100\n",
      "Epoch 693/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6800 - val_loss: 0.6794 - val_accuracy: 0.6100\n",
      "Epoch 694/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6725 - val_loss: 0.6650 - val_accuracy: 0.6300\n",
      "Epoch 695/1000\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.6149 - accuracy: 0.67 - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6950 - val_loss: 0.6952 - val_accuracy: 0.6100\n",
      "Epoch 696/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6825 - val_loss: 0.6779 - val_accuracy: 0.5900\n",
      "Epoch 697/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5883 - accuracy: 0.6850 - val_loss: 0.6829 - val_accuracy: 0.5800\n",
      "Epoch 698/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.6975 - val_loss: 0.6956 - val_accuracy: 0.5800\n",
      "Epoch 699/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.6750 - val_loss: 0.6882 - val_accuracy: 0.5900\n",
      "Epoch 700/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6034 - accuracy: 0.6825 - val_loss: 0.6897 - val_accuracy: 0.6100\n",
      "Epoch 701/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6650 - val_loss: 0.6843 - val_accuracy: 0.6200\n",
      "Epoch 702/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6925 - val_loss: 0.6860 - val_accuracy: 0.6100\n",
      "Epoch 703/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5972 - accuracy: 0.6925 - val_loss: 0.6847 - val_accuracy: 0.5900\n",
      "Epoch 704/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6525 - val_loss: 0.6926 - val_accuracy: 0.5800\n",
      "Epoch 705/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5914 - accuracy: 0.6925 - val_loss: 0.7109 - val_accuracy: 0.5600\n",
      "Epoch 706/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6700 - val_loss: 0.7002 - val_accuracy: 0.5900\n",
      "Epoch 707/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.6650 - val_loss: 0.6975 - val_accuracy: 0.5800\n",
      "Epoch 708/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6825 - val_loss: 0.6953 - val_accuracy: 0.5800\n",
      "Epoch 709/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6925 - val_loss: 0.6836 - val_accuracy: 0.6100\n",
      "Epoch 710/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6925 - val_loss: 0.6925 - val_accuracy: 0.5600\n",
      "Epoch 711/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.6775 - val_loss: 0.6843 - val_accuracy: 0.6200\n",
      "Epoch 712/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5963 - accuracy: 0.6800 - val_loss: 0.6903 - val_accuracy: 0.6200\n",
      "Epoch 713/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6900 - val_loss: 0.6947 - val_accuracy: 0.5900\n",
      "Epoch 714/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6700 - val_loss: 0.6905 - val_accuracy: 0.5900\n",
      "Epoch 715/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6900 - val_loss: 0.6953 - val_accuracy: 0.6200\n",
      "Epoch 716/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6550 - val_loss: 0.6882 - val_accuracy: 0.6000\n",
      "Epoch 717/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6900 - val_loss: 0.6911 - val_accuracy: 0.5900\n",
      "Epoch 718/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.7075 - val_loss: 0.6932 - val_accuracy: 0.5800\n",
      "Epoch 719/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6825 - val_loss: 0.6872 - val_accuracy: 0.5800\n",
      "Epoch 720/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5882 - accuracy: 0.6950 - val_loss: 0.6966 - val_accuracy: 0.5800\n",
      "Epoch 721/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.6975 - val_loss: 0.6967 - val_accuracy: 0.5800\n",
      "Epoch 722/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6850 - val_loss: 0.6938 - val_accuracy: 0.5900\n",
      "Epoch 723/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6775 - val_loss: 0.6837 - val_accuracy: 0.6200\n",
      "Epoch 724/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.7025 - val_loss: 0.6964 - val_accuracy: 0.6100\n",
      "Epoch 725/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6750 - val_loss: 0.7040 - val_accuracy: 0.5700\n",
      "Epoch 726/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6017 - accuracy: 0.6750 - val_loss: 0.6869 - val_accuracy: 0.6000\n",
      "Epoch 727/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6850 - val_loss: 0.6819 - val_accuracy: 0.6000\n",
      "Epoch 728/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6086 - accuracy: 0.6800 - val_loss: 0.6667 - val_accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.6825 - val_loss: 0.6773 - val_accuracy: 0.5900\n",
      "Epoch 730/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6241 - accuracy: 0.6450 - val_loss: 0.6823 - val_accuracy: 0.5900\n",
      "Epoch 731/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6675 - val_loss: 0.6788 - val_accuracy: 0.6000\n",
      "Epoch 732/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6029 - accuracy: 0.6875 - val_loss: 0.6797 - val_accuracy: 0.6000\n",
      "Epoch 733/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5924 - accuracy: 0.6850 - val_loss: 0.6715 - val_accuracy: 0.6100\n",
      "Epoch 734/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5836 - accuracy: 0.6925 - val_loss: 0.6838 - val_accuracy: 0.6000\n",
      "Epoch 735/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5926 - accuracy: 0.6775 - val_loss: 0.6827 - val_accuracy: 0.6000\n",
      "Epoch 736/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6825 - val_loss: 0.6841 - val_accuracy: 0.6100\n",
      "Epoch 737/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6013 - accuracy: 0.6925 - val_loss: 0.6855 - val_accuracy: 0.5800\n",
      "Epoch 738/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5979 - accuracy: 0.6925 - val_loss: 0.6841 - val_accuracy: 0.6000\n",
      "Epoch 739/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5927 - accuracy: 0.6750 - val_loss: 0.6843 - val_accuracy: 0.6100\n",
      "Epoch 740/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5955 - accuracy: 0.7075 - val_loss: 0.6843 - val_accuracy: 0.6300\n",
      "Epoch 741/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6800 - val_loss: 0.6682 - val_accuracy: 0.6200\n",
      "Epoch 742/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6900 - val_loss: 0.6870 - val_accuracy: 0.6000\n",
      "Epoch 743/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6006 - accuracy: 0.6950 - val_loss: 0.6787 - val_accuracy: 0.6300\n",
      "Epoch 744/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.6775 - val_loss: 0.6800 - val_accuracy: 0.6000\n",
      "Epoch 745/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5932 - accuracy: 0.6850 - val_loss: 0.6843 - val_accuracy: 0.6000\n",
      "Epoch 746/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5899 - accuracy: 0.6775 - val_loss: 0.6839 - val_accuracy: 0.6100\n",
      "Epoch 747/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6925 - val_loss: 0.6868 - val_accuracy: 0.6100\n",
      "Epoch 748/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6850 - val_loss: 0.6895 - val_accuracy: 0.6000\n",
      "Epoch 749/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5877 - accuracy: 0.6875 - val_loss: 0.7064 - val_accuracy: 0.5700\n",
      "Epoch 750/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6725 - val_loss: 0.6916 - val_accuracy: 0.6000\n",
      "Epoch 751/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6850 - val_loss: 0.6842 - val_accuracy: 0.5700\n",
      "Epoch 752/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6750 - val_loss: 0.7117 - val_accuracy: 0.5800\n",
      "Epoch 753/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6825 - val_loss: 0.7041 - val_accuracy: 0.5800\n",
      "Epoch 754/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5866 - accuracy: 0.6875 - val_loss: 0.6989 - val_accuracy: 0.5800\n",
      "Epoch 755/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6875 - val_loss: 0.7117 - val_accuracy: 0.6000\n",
      "Epoch 756/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6775 - val_loss: 0.6811 - val_accuracy: 0.6000\n",
      "Epoch 757/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.6875 - val_loss: 0.6867 - val_accuracy: 0.5800\n",
      "Epoch 758/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.7025 - val_loss: 0.6887 - val_accuracy: 0.6100\n",
      "Epoch 759/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5841 - accuracy: 0.6925 - val_loss: 0.6878 - val_accuracy: 0.5800\n",
      "Epoch 760/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6875 - val_loss: 0.6842 - val_accuracy: 0.5900\n",
      "Epoch 761/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5777 - accuracy: 0.6925 - val_loss: 0.7134 - val_accuracy: 0.5800\n",
      "Epoch 762/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6950 - val_loss: 0.6859 - val_accuracy: 0.6100\n",
      "Epoch 763/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6850 - val_loss: 0.6863 - val_accuracy: 0.5900\n",
      "Epoch 764/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6002 - accuracy: 0.6825 - val_loss: 0.6623 - val_accuracy: 0.5900\n",
      "Epoch 765/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5872 - accuracy: 0.6775 - val_loss: 0.6745 - val_accuracy: 0.5800\n",
      "Epoch 766/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.7075 - val_loss: 0.6810 - val_accuracy: 0.5800\n",
      "Epoch 767/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6018 - accuracy: 0.6925 - val_loss: 0.6654 - val_accuracy: 0.6200\n",
      "Epoch 768/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.6850 - val_loss: 0.6699 - val_accuracy: 0.5800\n",
      "Epoch 769/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6575 - val_loss: 0.6823 - val_accuracy: 0.5900\n",
      "Epoch 770/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5923 - accuracy: 0.6700 - val_loss: 0.6971 - val_accuracy: 0.5800\n",
      "Epoch 771/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6775 - val_loss: 0.6904 - val_accuracy: 0.5900\n",
      "Epoch 772/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.7100 - val_loss: 0.7033 - val_accuracy: 0.6000\n",
      "Epoch 773/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.6850 - val_loss: 0.7037 - val_accuracy: 0.5800\n",
      "Epoch 774/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6875 - val_loss: 0.7077 - val_accuracy: 0.6000\n",
      "Epoch 775/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5904 - accuracy: 0.6850 - val_loss: 0.6961 - val_accuracy: 0.6000\n",
      "Epoch 776/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5764 - accuracy: 0.6875 - val_loss: 0.7023 - val_accuracy: 0.5900\n",
      "Epoch 777/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7100 - val_loss: 0.7087 - val_accuracy: 0.5900\n",
      "Epoch 778/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5954 - accuracy: 0.6875 - val_loss: 0.7225 - val_accuracy: 0.5700\n",
      "Epoch 779/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6825 - val_loss: 0.7166 - val_accuracy: 0.5700\n",
      "Epoch 780/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6850 - val_loss: 0.7033 - val_accuracy: 0.5700\n",
      "Epoch 781/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5749 - accuracy: 0.6975 - val_loss: 0.7176 - val_accuracy: 0.5800\n",
      "Epoch 782/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5794 - accuracy: 0.6700 - val_loss: 0.7087 - val_accuracy: 0.5900\n",
      "Epoch 783/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6800 - val_loss: 0.7116 - val_accuracy: 0.6100\n",
      "Epoch 784/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6950 - val_loss: 0.7120 - val_accuracy: 0.5900\n",
      "Epoch 785/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.6750 - val_loss: 0.7121 - val_accuracy: 0.5900\n",
      "Epoch 786/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5954 - accuracy: 0.6750 - val_loss: 0.7193 - val_accuracy: 0.6000\n",
      "Epoch 787/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6725 - val_loss: 0.7270 - val_accuracy: 0.5800\n",
      "Epoch 788/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5811 - accuracy: 0.7050 - val_loss: 0.7293 - val_accuracy: 0.5800\n",
      "Epoch 789/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.6850 - val_loss: 0.7256 - val_accuracy: 0.5700\n",
      "Epoch 790/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6925 - val_loss: 0.7139 - val_accuracy: 0.5700\n",
      "Epoch 791/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7000 - val_loss: 0.7191 - val_accuracy: 0.5700\n",
      "Epoch 792/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5628 - accuracy: 0.7200 - val_loss: 0.7180 - val_accuracy: 0.5900\n",
      "Epoch 793/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5847 - accuracy: 0.6850 - val_loss: 0.7399 - val_accuracy: 0.5900\n",
      "Epoch 794/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6850 - val_loss: 0.7078 - val_accuracy: 0.5800\n",
      "Epoch 795/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.7050 - val_loss: 0.7017 - val_accuracy: 0.5800\n",
      "Epoch 796/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.6900 - val_loss: 0.7008 - val_accuracy: 0.5800\n",
      "Epoch 797/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.6975 - val_loss: 0.7148 - val_accuracy: 0.6000\n",
      "Epoch 798/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6900 - val_loss: 0.7327 - val_accuracy: 0.6000\n",
      "Epoch 799/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.7025 - val_loss: 0.7348 - val_accuracy: 0.5900\n",
      "Epoch 800/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5844 - accuracy: 0.6825 - val_loss: 0.7352 - val_accuracy: 0.5800\n",
      "Epoch 801/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5913 - accuracy: 0.7100 - val_loss: 0.7240 - val_accuracy: 0.5900\n",
      "Epoch 802/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5789 - accuracy: 0.6900 - val_loss: 0.7270 - val_accuracy: 0.5900\n",
      "Epoch 803/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6750 - val_loss: 0.7070 - val_accuracy: 0.5500\n",
      "Epoch 804/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5796 - accuracy: 0.6775 - val_loss: 0.7119 - val_accuracy: 0.5600\n",
      "Epoch 805/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5909 - accuracy: 0.6850 - val_loss: 0.7082 - val_accuracy: 0.5900\n",
      "Epoch 806/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5965 - accuracy: 0.6850 - val_loss: 0.7090 - val_accuracy: 0.5700\n",
      "Epoch 807/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6675 - val_loss: 0.7114 - val_accuracy: 0.5700\n",
      "Epoch 808/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6060 - accuracy: 0.6725 - val_loss: 0.6877 - val_accuracy: 0.5900\n",
      "Epoch 809/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.6675 - val_loss: 0.7012 - val_accuracy: 0.5900\n",
      "Epoch 810/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5917 - accuracy: 0.6850 - val_loss: 0.6941 - val_accuracy: 0.5700\n",
      "Epoch 811/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5774 - accuracy: 0.6950 - val_loss: 0.6966 - val_accuracy: 0.5700\n",
      "Epoch 812/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6975 - val_loss: 0.7092 - val_accuracy: 0.5700\n",
      "Epoch 813/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6875 - val_loss: 0.7022 - val_accuracy: 0.5800\n",
      "Epoch 814/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.6775 - val_loss: 0.6950 - val_accuracy: 0.5800\n",
      "Epoch 815/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.6925 - val_loss: 0.7017 - val_accuracy: 0.6100\n",
      "Epoch 816/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.6900 - val_loss: 0.7045 - val_accuracy: 0.5800\n",
      "Epoch 817/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.6875 - val_loss: 0.6998 - val_accuracy: 0.5700\n",
      "Epoch 818/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.6750 - val_loss: 0.6975 - val_accuracy: 0.5500\n",
      "Epoch 819/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6775 - val_loss: 0.6875 - val_accuracy: 0.5700\n",
      "Epoch 820/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5685 - accuracy: 0.6775 - val_loss: 0.6955 - val_accuracy: 0.5800\n",
      "Epoch 821/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6875 - val_loss: 0.7054 - val_accuracy: 0.5600\n",
      "Epoch 822/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.6850 - val_loss: 0.7040 - val_accuracy: 0.5500\n",
      "Epoch 823/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.6975 - val_loss: 0.7014 - val_accuracy: 0.5900\n",
      "Epoch 824/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5888 - accuracy: 0.6875 - val_loss: 0.7189 - val_accuracy: 0.5600\n",
      "Epoch 825/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6900 - val_loss: 0.7151 - val_accuracy: 0.5600\n",
      "Epoch 826/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.6825 - val_loss: 0.7409 - val_accuracy: 0.6000\n",
      "Epoch 827/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5966 - accuracy: 0.6900 - val_loss: 0.7041 - val_accuracy: 0.6000\n",
      "Epoch 828/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5751 - accuracy: 0.6850 - val_loss: 0.7052 - val_accuracy: 0.5700\n",
      "Epoch 829/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.6900 - val_loss: 0.6931 - val_accuracy: 0.5700\n",
      "Epoch 830/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5687 - accuracy: 0.6900 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 831/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6900 - val_loss: 0.6880 - val_accuracy: 0.5900\n",
      "Epoch 832/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.6950 - val_loss: 0.7018 - val_accuracy: 0.6000\n",
      "Epoch 833/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.7050 - val_loss: 0.7039 - val_accuracy: 0.5900\n",
      "Epoch 834/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6111 - accuracy: 0.6900 - val_loss: 0.7236 - val_accuracy: 0.5700\n",
      "Epoch 835/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6725 - val_loss: 0.7121 - val_accuracy: 0.5900\n",
      "Epoch 836/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.6750 - val_loss: 0.7479 - val_accuracy: 0.5800\n",
      "Epoch 837/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.6900 - val_loss: 0.7644 - val_accuracy: 0.5900\n",
      "Epoch 838/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5962 - accuracy: 0.6950 - val_loss: 0.7548 - val_accuracy: 0.5900\n",
      "Epoch 839/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.6725 - val_loss: 0.7445 - val_accuracy: 0.5900\n",
      "Epoch 840/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.6675 - val_loss: 0.7139 - val_accuracy: 0.6300\n",
      "Epoch 841/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5820 - accuracy: 0.6975 - val_loss: 0.7151 - val_accuracy: 0.5900\n",
      "Epoch 842/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6950 - val_loss: 0.7233 - val_accuracy: 0.5700\n",
      "Epoch 843/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6950 - val_loss: 0.7506 - val_accuracy: 0.5800\n",
      "Epoch 844/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6900 - val_loss: 0.7524 - val_accuracy: 0.5800\n",
      "Epoch 845/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.6800 - val_loss: 0.7390 - val_accuracy: 0.6000\n",
      "Epoch 846/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6800 - val_loss: 0.7701 - val_accuracy: 0.5700\n",
      "Epoch 847/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.6775 - val_loss: 0.7493 - val_accuracy: 0.6000\n",
      "Epoch 848/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5806 - accuracy: 0.6825 - val_loss: 0.7414 - val_accuracy: 0.5900\n",
      "Epoch 849/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5657 - accuracy: 0.7125 - val_loss: 0.7519 - val_accuracy: 0.6000\n",
      "Epoch 850/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5852 - accuracy: 0.6675 - val_loss: 0.7516 - val_accuracy: 0.5900\n",
      "Epoch 851/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.7025 - val_loss: 0.7585 - val_accuracy: 0.6000\n",
      "Epoch 852/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.6875 - val_loss: 0.7409 - val_accuracy: 0.6300\n",
      "Epoch 853/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5762 - accuracy: 0.6950 - val_loss: 0.7481 - val_accuracy: 0.6000\n",
      "Epoch 854/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5868 - accuracy: 0.6925 - val_loss: 0.7276 - val_accuracy: 0.5900\n",
      "Epoch 855/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.6800 - val_loss: 0.7128 - val_accuracy: 0.5800\n",
      "Epoch 856/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5886 - accuracy: 0.6625 - val_loss: 0.7200 - val_accuracy: 0.5800\n",
      "Epoch 857/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6925 - val_loss: 0.7277 - val_accuracy: 0.5700\n",
      "Epoch 858/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.6775 - val_loss: 0.7352 - val_accuracy: 0.5900\n",
      "Epoch 859/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5706 - accuracy: 0.7150 - val_loss: 0.7279 - val_accuracy: 0.5900\n",
      "Epoch 860/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6850 - val_loss: 0.7481 - val_accuracy: 0.5900\n",
      "Epoch 861/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5945 - accuracy: 0.6950 - val_loss: 0.7409 - val_accuracy: 0.5900\n",
      "Epoch 862/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.7000 - val_loss: 0.7558 - val_accuracy: 0.5900\n",
      "Epoch 863/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.7025 - val_loss: 0.7070 - val_accuracy: 0.5900\n",
      "Epoch 864/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5918 - accuracy: 0.6900 - val_loss: 0.7563 - val_accuracy: 0.5800\n",
      "Epoch 865/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.6950 - val_loss: 0.8027 - val_accuracy: 0.5800\n",
      "Epoch 866/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6021 - accuracy: 0.6675 - val_loss: 0.7619 - val_accuracy: 0.6200\n",
      "Epoch 867/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6875 - val_loss: 0.6900 - val_accuracy: 0.5800\n",
      "Epoch 868/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5862 - accuracy: 0.6800 - val_loss: 0.6797 - val_accuracy: 0.6200\n",
      "Epoch 869/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6775 - val_loss: 0.6867 - val_accuracy: 0.5800\n",
      "Epoch 870/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5898 - accuracy: 0.6725 - val_loss: 0.6997 - val_accuracy: 0.5700\n",
      "Epoch 871/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5833 - accuracy: 0.6900 - val_loss: 0.7467 - val_accuracy: 0.6100\n",
      "Epoch 872/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.6775 - val_loss: 0.7532 - val_accuracy: 0.6100\n",
      "Epoch 873/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6950 - val_loss: 0.7471 - val_accuracy: 0.6100\n",
      "Epoch 874/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.7000 - val_loss: 0.7482 - val_accuracy: 0.6100\n",
      "Epoch 875/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.6850 - val_loss: 0.7533 - val_accuracy: 0.5800\n",
      "Epoch 876/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5683 - accuracy: 0.7000 - val_loss: 0.7634 - val_accuracy: 0.5800\n",
      "Epoch 877/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5800 - accuracy: 0.7000 - val_loss: 0.7668 - val_accuracy: 0.6000\n",
      "Epoch 878/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6900 - val_loss: 0.7612 - val_accuracy: 0.6000\n",
      "Epoch 879/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5788 - accuracy: 0.6825 - val_loss: 0.7626 - val_accuracy: 0.6000\n",
      "Epoch 880/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5891 - accuracy: 0.6600 - val_loss: 0.7602 - val_accuracy: 0.6000\n",
      "Epoch 881/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.6875 - val_loss: 0.7638 - val_accuracy: 0.6000\n",
      "Epoch 882/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5830 - accuracy: 0.7000 - val_loss: 0.7625 - val_accuracy: 0.5900\n",
      "Epoch 883/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5980 - accuracy: 0.7075 - val_loss: 0.7551 - val_accuracy: 0.5800\n",
      "Epoch 884/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5922 - accuracy: 0.6775 - val_loss: 0.7485 - val_accuracy: 0.5800\n",
      "Epoch 885/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5807 - accuracy: 0.7175 - val_loss: 0.7492 - val_accuracy: 0.5800\n",
      "Epoch 886/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.7000 - val_loss: 0.7489 - val_accuracy: 0.6200\n",
      "Epoch 887/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6975 - val_loss: 0.7366 - val_accuracy: 0.6200\n",
      "Epoch 888/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.6825 - val_loss: 0.7357 - val_accuracy: 0.6000\n",
      "Epoch 889/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5799 - accuracy: 0.6850 - val_loss: 0.7372 - val_accuracy: 0.6100\n",
      "Epoch 890/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7025 - val_loss: 0.7291 - val_accuracy: 0.6100\n",
      "Epoch 891/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.6825 - val_loss: 0.7489 - val_accuracy: 0.6000\n",
      "Epoch 892/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6925 - val_loss: 0.7386 - val_accuracy: 0.6200\n",
      "Epoch 893/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6825 - val_loss: 0.7362 - val_accuracy: 0.6200\n",
      "Epoch 894/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.6925 - val_loss: 0.7401 - val_accuracy: 0.5900\n",
      "Epoch 895/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7025 - val_loss: 0.7567 - val_accuracy: 0.5800\n",
      "Epoch 896/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5726 - accuracy: 0.7000 - val_loss: 0.7535 - val_accuracy: 0.5700\n",
      "Epoch 897/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5742 - accuracy: 0.6850 - val_loss: 0.7701 - val_accuracy: 0.5700\n",
      "Epoch 898/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.6850 - val_loss: 0.7534 - val_accuracy: 0.5900\n",
      "Epoch 899/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5768 - accuracy: 0.6900 - val_loss: 0.7559 - val_accuracy: 0.5900\n",
      "Epoch 900/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7075 - val_loss: 0.7620 - val_accuracy: 0.5900\n",
      "Epoch 901/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.6950 - val_loss: 0.7590 - val_accuracy: 0.5900\n",
      "Epoch 902/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.7025 - val_loss: 0.7568 - val_accuracy: 0.5900\n",
      "Epoch 903/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6725 - val_loss: 0.7490 - val_accuracy: 0.5900\n",
      "Epoch 904/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.6850 - val_loss: 0.7623 - val_accuracy: 0.5900\n",
      "Epoch 905/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6975 - val_loss: 0.7164 - val_accuracy: 0.5900\n",
      "Epoch 906/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5738 - accuracy: 0.7025 - val_loss: 0.7528 - val_accuracy: 0.6200\n",
      "Epoch 907/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.7050 - val_loss: 0.7682 - val_accuracy: 0.5700\n",
      "Epoch 908/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.7100 - val_loss: 0.7804 - val_accuracy: 0.5700\n",
      "Epoch 909/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.6900 - val_loss: 0.7630 - val_accuracy: 0.5700\n",
      "Epoch 910/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5614 - accuracy: 0.6925 - val_loss: 0.7957 - val_accuracy: 0.5700\n",
      "Epoch 911/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5948 - accuracy: 0.6925 - val_loss: 0.7537 - val_accuracy: 0.5700\n",
      "Epoch 912/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5773 - accuracy: 0.6875 - val_loss: 0.7663 - val_accuracy: 0.5700\n",
      "Epoch 913/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7050 - val_loss: 0.7789 - val_accuracy: 0.6000\n",
      "Epoch 914/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6900 - val_loss: 0.7641 - val_accuracy: 0.5600\n",
      "Epoch 915/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5820 - accuracy: 0.7200 - val_loss: 0.7607 - val_accuracy: 0.5800\n",
      "Epoch 916/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6875 - val_loss: 0.7352 - val_accuracy: 0.5700\n",
      "Epoch 917/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6900 - val_loss: 0.7446 - val_accuracy: 0.5700\n",
      "Epoch 918/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.6675 - val_loss: 0.7413 - val_accuracy: 0.5600\n",
      "Epoch 919/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5753 - accuracy: 0.6900 - val_loss: 0.7537 - val_accuracy: 0.5700\n",
      "Epoch 920/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.6875 - val_loss: 0.7485 - val_accuracy: 0.5800\n",
      "Epoch 921/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.6825 - val_loss: 0.7528 - val_accuracy: 0.5800\n",
      "Epoch 922/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.7100 - val_loss: 0.7532 - val_accuracy: 0.5800\n",
      "Epoch 923/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.6725 - val_loss: 0.7358 - val_accuracy: 0.5800\n",
      "Epoch 924/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7075 - val_loss: 0.7351 - val_accuracy: 0.5700\n",
      "Epoch 925/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.6975 - val_loss: 0.7233 - val_accuracy: 0.5700\n",
      "Epoch 926/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5876 - accuracy: 0.6925 - val_loss: 0.7362 - val_accuracy: 0.5800\n",
      "Epoch 927/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5869 - accuracy: 0.7025 - val_loss: 0.7334 - val_accuracy: 0.5800\n",
      "Epoch 928/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.6700 - val_loss: 0.7095 - val_accuracy: 0.5900\n",
      "Epoch 929/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5815 - accuracy: 0.6825 - val_loss: 0.7355 - val_accuracy: 0.5800\n",
      "Epoch 930/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.7000 - val_loss: 0.7315 - val_accuracy: 0.5800\n",
      "Epoch 931/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6975 - val_loss: 0.7404 - val_accuracy: 0.5800\n",
      "Epoch 932/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5888 - accuracy: 0.6800 - val_loss: 0.7215 - val_accuracy: 0.5900\n",
      "Epoch 933/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7050 - val_loss: 0.7439 - val_accuracy: 0.6200\n",
      "Epoch 934/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7100 - val_loss: 0.7692 - val_accuracy: 0.6000\n",
      "Epoch 935/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5776 - accuracy: 0.6850 - val_loss: 0.7555 - val_accuracy: 0.6100\n",
      "Epoch 936/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6975 - val_loss: 0.7021 - val_accuracy: 0.5800\n",
      "Epoch 937/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7075 - val_loss: 0.7197 - val_accuracy: 0.6000\n",
      "Epoch 938/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.6900 - val_loss: 0.7333 - val_accuracy: 0.5800\n",
      "Epoch 939/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5672 - accuracy: 0.6950 - val_loss: 0.7306 - val_accuracy: 0.5800\n",
      "Epoch 940/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5751 - accuracy: 0.6975 - val_loss: 0.7283 - val_accuracy: 0.5800\n",
      "Epoch 941/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.7075 - val_loss: 0.7167 - val_accuracy: 0.6000\n",
      "Epoch 942/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7000 - val_loss: 0.7091 - val_accuracy: 0.6100\n",
      "Epoch 943/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7050 - val_loss: 0.7244 - val_accuracy: 0.5900\n",
      "Epoch 944/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7025 - val_loss: 0.7275 - val_accuracy: 0.5900\n",
      "Epoch 945/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.6950 - val_loss: 0.7283 - val_accuracy: 0.5700\n",
      "Epoch 946/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.6900 - val_loss: 0.7332 - val_accuracy: 0.5800\n",
      "Epoch 947/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5676 - accuracy: 0.6925 - val_loss: 0.7374 - val_accuracy: 0.5700\n",
      "Epoch 948/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.6925 - val_loss: 0.7397 - val_accuracy: 0.5700\n",
      "Epoch 949/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6975 - val_loss: 0.7353 - val_accuracy: 0.5700\n",
      "Epoch 950/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5816 - accuracy: 0.6925 - val_loss: 0.7390 - val_accuracy: 0.6000\n",
      "Epoch 951/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7000 - val_loss: 0.7133 - val_accuracy: 0.5800\n",
      "Epoch 952/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5724 - accuracy: 0.6900 - val_loss: 0.7269 - val_accuracy: 0.6200\n",
      "Epoch 953/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.6975 - val_loss: 0.7294 - val_accuracy: 0.5900\n",
      "Epoch 954/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.6825 - val_loss: 0.7178 - val_accuracy: 0.6300\n",
      "Epoch 955/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5790 - accuracy: 0.6725 - val_loss: 0.7176 - val_accuracy: 0.6100\n",
      "Epoch 956/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6925 - val_loss: 0.7231 - val_accuracy: 0.6100\n",
      "Epoch 957/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7125 - val_loss: 0.7224 - val_accuracy: 0.5700\n",
      "Epoch 958/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6975 - val_loss: 0.7380 - val_accuracy: 0.5700\n",
      "Epoch 959/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.6975 - val_loss: 0.7399 - val_accuracy: 0.6000\n",
      "Epoch 960/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5645 - accuracy: 0.6975 - val_loss: 0.7158 - val_accuracy: 0.5600\n",
      "Epoch 961/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6875 - val_loss: 0.7510 - val_accuracy: 0.5900\n",
      "Epoch 962/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.6975 - val_loss: 0.7219 - val_accuracy: 0.5800\n",
      "Epoch 963/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7050 - val_loss: 0.7285 - val_accuracy: 0.5800\n",
      "Epoch 964/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.7000 - val_loss: 0.7206 - val_accuracy: 0.5800\n",
      "Epoch 965/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.7100 - val_loss: 0.7312 - val_accuracy: 0.5800\n",
      "Epoch 966/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5843 - accuracy: 0.6800 - val_loss: 0.7452 - val_accuracy: 0.5800\n",
      "Epoch 967/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5686 - accuracy: 0.7125 - val_loss: 0.7574 - val_accuracy: 0.5700\n",
      "Epoch 968/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5736 - accuracy: 0.6975 - val_loss: 0.7553 - val_accuracy: 0.5600\n",
      "Epoch 969/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.6875 - val_loss: 0.7504 - val_accuracy: 0.5700\n",
      "Epoch 970/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5855 - accuracy: 0.6900 - val_loss: 0.7239 - val_accuracy: 0.5700\n",
      "Epoch 971/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5602 - accuracy: 0.7000 - val_loss: 0.7437 - val_accuracy: 0.5700\n",
      "Epoch 972/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5624 - accuracy: 0.7150 - val_loss: 0.7667 - val_accuracy: 0.5600\n",
      "Epoch 973/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.6032 - accuracy: 0.6950 - val_loss: 0.7581 - val_accuracy: 0.5700\n",
      "Epoch 974/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.7000 - val_loss: 0.7395 - val_accuracy: 0.5700\n",
      "Epoch 975/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5850 - accuracy: 0.6975 - val_loss: 0.7561 - val_accuracy: 0.5700\n",
      "Epoch 976/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5761 - accuracy: 0.6850 - val_loss: 0.7603 - val_accuracy: 0.5700\n",
      "Epoch 977/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5808 - accuracy: 0.6900 - val_loss: 0.7615 - val_accuracy: 0.5700\n",
      "Epoch 978/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5720 - accuracy: 0.6825 - val_loss: 0.7718 - val_accuracy: 0.5600\n",
      "Epoch 979/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7075 - val_loss: 0.7766 - val_accuracy: 0.5600\n",
      "Epoch 980/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.6750 - val_loss: 0.7727 - val_accuracy: 0.5600\n",
      "Epoch 981/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7100 - val_loss: 0.7913 - val_accuracy: 0.5700\n",
      "Epoch 982/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5729 - accuracy: 0.6900 - val_loss: 0.8337 - val_accuracy: 0.5700\n",
      "Epoch 983/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5672 - accuracy: 0.7075 - val_loss: 0.8357 - val_accuracy: 0.5700\n",
      "Epoch 984/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5878 - accuracy: 0.6900 - val_loss: 0.7868 - val_accuracy: 0.5800\n",
      "Epoch 985/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5690 - accuracy: 0.7025 - val_loss: 0.7352 - val_accuracy: 0.5800\n",
      "Epoch 986/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.6950 - val_loss: 0.7677 - val_accuracy: 0.5700\n",
      "Epoch 987/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5846 - accuracy: 0.7050 - val_loss: 0.7672 - val_accuracy: 0.5800\n",
      "Epoch 988/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6925 - val_loss: 0.7751 - val_accuracy: 0.6000\n",
      "Epoch 989/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6900 - val_loss: 0.7665 - val_accuracy: 0.5700\n",
      "Epoch 990/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.7175 - val_loss: 0.7532 - val_accuracy: 0.5800\n",
      "Epoch 991/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.7025 - val_loss: 0.7600 - val_accuracy: 0.5800\n",
      "Epoch 992/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5863 - accuracy: 0.7000 - val_loss: 0.7689 - val_accuracy: 0.5800\n",
      "Epoch 993/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5792 - accuracy: 0.6900 - val_loss: 0.7609 - val_accuracy: 0.6100\n",
      "Epoch 994/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.7025 - val_loss: 0.7531 - val_accuracy: 0.5700\n",
      "Epoch 995/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7025 - val_loss: 0.7742 - val_accuracy: 0.5800\n",
      "Epoch 996/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6975 - val_loss: 0.7678 - val_accuracy: 0.5600\n",
      "Epoch 997/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.6775 - val_loss: 0.7794 - val_accuracy: 0.5800\n",
      "Epoch 998/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5769 - accuracy: 0.6950 - val_loss: 0.8192 - val_accuracy: 0.5700\n",
      "Epoch 999/1000\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.5935 - accuracy: 0.6900 - val_loss: 0.7648 - val_accuracy: 0.5900\n",
      "Epoch 1000/1000\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.6850 - val_loss: 0.7732 - val_accuracy: 0.5800\n",
      "Training completed in time:  0:02:18.542431\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "num_batch_size = 4\n",
    "start = datetime.now()\n",
    "\n",
    "history=model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs,validation_data=(x_test, y_test),  verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7124999761581421\n",
      "Testing Accuracy:  0.5799999833106995\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
